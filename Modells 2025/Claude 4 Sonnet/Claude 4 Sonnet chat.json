  provide a complete ready-to-run Python implementation for a U-Net architecture using PyTorch, for binary segmentation of grayscale images. The dataset should consist of grayscale images and corresponding binary masks, which are located in 2 different folders or in the same path (the masks have the same name as the images, with a suffix, like: "number.png" and the masks "number_seg.png", around 5000 samples in total. access and split directly using train_test_split on the index list and Subset, and do NOT duplicate or copy to new directory). It should work and provide correct predictions, and save the losses and dice scores as instructed below. The code should be structured into importable scripts with the following:
1.  A custom Dataset class for loading the grayscale images and corresponding binary masks. (only the png files, ignore meta files or additional files in the directory)
2.  A UNet model class definition using PyTorch, optimized for binary segmentation (with small foreground, mostly background)
3.  Functions for the training procedure, validation procedure, and Testing procedure.
Considerations for each part:
4.  Ensure needed transforms on input image and mask pairs (Re-size images correctly, ensure gray scale and binary…)
5.  Avoid overfitting and data leakage (without using augmentations), choose appropriate hyperparameters, learning rate, batch size, etc
•  For Training and Validation:
6.  Compute training and validation losses.
7.  Track and save the average training loss for each epoch in a separate Excel file (train_losses.xlsx) in a given save path. The first row should contain the epoch numbers, and the second row should contain the corresponding average training loss for each epoch.
8.  Similarly, save the validation loss for each epoch in an Excel file (val_losses.xlsx) with the same structure.
9.  At the end of training, save both the entire model and the model's state dictionary (.pth files) in the save path
10.  Calculate total training time from start to end, and print at the end of training
11.  The progress, phase (train/validation), and all info should be shown epoch by epoch using tqdm progress bars during training, validation, and testing.
12.  A function to visualize training losses and validation losses over epochs afterwards, on the same plot. Save plot in a specified save path as png. 
13.  During Validation: mean Dice scores should be calculated over each batch, for each epoch, and stored in an Excel file (epochs as rows and batches as columns). The Excel file (named “validation_dice_scores” should be saved at the specified save path after validation is done.
14.  Do the same for the Testing and store dice the Dice scores the same way and save the excel file as “test_dice_scores” after testing is done.
•  For Testing:
15.  A function to visualize the predicted masks, the input image, and the ground truth, for 5 random samples, after testing is done. (subplots for 5 random samples in one plot, in 5 rows and 3 columns (title at top: Input Image, Ground Truth, Prediction). Also display image file name string above each image and mask. save the plot as .png).
•  For Main:
16.  Shuffle the data, split the dataset into: 80% training, 10% validation, and 10% test sets using train_test_split. Print the sizes of each (how many images), and copy the splitted data (images and their respective masks) 
17.  DataLoader setup for training, validation, and testing sets.
18.  Ensure correct data loading, print data loader sizes.
19.  Also usig torchinfo, print model summary, and total number of model parameters (n learnable params). 
20.  All the above functionalities should be implemented in a modular way so that they can be imported as scripts or classes.
21.  All visualizations should just be saved as png. No need to display the plots during running.
22.  Ensure that everything can be executed in an if name == "main": block with instructions for loading the dataset, configuring hyperparameters, and saving the trained model.
The directory structure should only be:
unet_segmentation/
├── dataset.py
├── model.py
├── train.py
├── main.py

Edit
I'll create a complete U-Net implementation for binary segmentation with all the requested functionality. Here are the modular scripts:

Dataset.py custom dataset class:

import os
import torch
from torch.utils.data import Dataset
from PIL import Image
import numpy as np
from torchvision import transforms

class SegmentationDataset(Dataset):
    def __init__(self, image_dir, mask_suffix='_seg', transform=None, image_size=(256, 256)):
        """
        Dataset for loading grayscale images and corresponding binary masks.
        
        Args:
            image_dir (str): Directory containing images and masks
            mask_suffix (str): Suffix for mask files (e.g., '_seg' for 'image_seg.png')
            transform (callable, optional): Optional transform to be applied
            image_size (tuple): Target size for images and masks
        """
        self.image_dir = image_dir
        self.mask_suffix = mask_suffix
        self.image_size = image_size
        
        # Get all PNG files
        all_files = [f for f in os.listdir(image_dir) if f.lower().endswith('.png')]
        
        # Filter out mask files and keep only original images
        self.image_files = []
        for f in all_files:
            if not f.replace('.png', '').endswith(mask_suffix):
                # Check if corresponding mask exists
                mask_name = f.replace('.png', f'{mask_suffix}.png')
                if mask_name in all_files:
                    self.image_files.append(f)
        
        self.image_files.sort()
        
        # Define transforms
        self.image_transform = transforms.Compose([
            transforms.Resize(image_size),
            transforms.ToTensor(),
        ])
        
        self.mask_transform = transforms.Compose([
            transforms.Resize(image_size, interpolation=transforms.InterpolationMode.NEAREST),
            transforms.ToTensor(),
        ])
        
        print(f"Found {len(self.image_files)} image-mask pairs")
    
    def __len__(self):
        return len(self.image_files)
    
    def __getitem__(self, idx):
        # Load image
        img_name = self.image_files[idx]
        img_path = os.path.join(self.image_dir, img_name)
        
        # Load mask
        mask_name = img_name.replace('.png', f'{self.mask_suffix}.png')
        mask_path = os.path.join(self.image_dir, mask_name)
        
        # Open and convert images
        image = Image.open(img_path).convert('L')  # Convert to grayscale
        mask = Image.open(mask_path).convert('L')   # Convert to grayscale
        
        # Apply transforms
        image = self.image_transform(image)
        mask = self.mask_transform(mask)
        
        # Ensure mask is binary (0 or 1)
        mask = (mask > 0.5).float()
        
        return image, mask, img_name

Model.py Unet mdoel definition:

import torch
import torch.nn as nn
import torch.nn.functional as F

class DoubleConv(nn.Module):
    """(convolution => [BN] => ReLU) * 2"""
    
    def __init__(self, in_channels, out_channels, mid_channels=None):
        super().__init__()
        if not mid_channels:
            mid_channels = out_channels
        self.double_conv = nn.Sequential(
            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(mid_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )

    def forward(self, x):
        return self.double_conv(x)


class Down(nn.Module):
    """Downscaling with maxpool then double conv"""

    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.maxpool_conv = nn.Sequential(
            nn.MaxPool2d(2),
            DoubleConv(in_channels, out_channels)
        )

    def forward(self, x):
        return self.maxpool_conv(x)


class Up(nn.Module):
    """Upscaling then double conv"""

    def __init__(self, in_channels, out_channels, bilinear=True):
        super().__init__()

        # if bilinear, use the normal convolutions to reduce the number of channels
        if bilinear:
            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)
            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)
        else:
            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)
            self.conv = DoubleConv(in_channels, out_channels)

    def forward(self, x1, x2):
        x1 = self.up(x1)
        # input is CHW
        diffY = x2.size()[2] - x1.size()[2]
        diffX = x2.size()[3] - x1.size()[3]

        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,
                        diffY // 2, diffY - diffY // 2])
        
        x = torch.cat([x2, x1], dim=1)
        return self.conv(x)


class OutConv(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(OutConv, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)

    def forward(self, x):
        return self.conv(x)


class UNet(nn.Module):
    """
    U-Net model for binary segmentation.
    Optimized for small foreground objects in mostly background images.
    """
    def __init__(self, n_channels=1, n_classes=1, bilinear=False):
        super(UNet, self).__init__()
        self.n_channels = n_channels
        self.n_classes = n_classes
        self.bilinear = bilinear

        self.inc = DoubleConv(n_channels, 64)
        self.down1 = Down(64, 128)
        self.down2 = Down(128, 256)
        self.down3 = Down(256, 512)
        factor = 2 if bilinear else 1
        self.down4 = Down(512, 1024 // factor)
        self.up1 = Up(1024, 512 // factor, bilinear)
        self.up2 = Up(512, 256 // factor, bilinear)
        self.up3 = Up(256, 128 // factor, bilinear)
        self.up4 = Up(128, 64, bilinear)
        self.outc = OutConv(64, n_classes)
        
        # Add dropout for regularization
        self.dropout = nn.Dropout2d(0.1)

    def forward(self, x):
        x1 = self.inc(x)
        x2 = self.down1(x1)
        x3 = self.down2(x2)
        x4 = self.down3(x3)
        x5 = self.down4(x4)
        x5 = self.dropout(x5)  # Add dropout at bottleneck
        
        x = self.up1(x5, x4)
        x = self.up2(x, x3)
        x = self.up3(x, x2)
        x = self.up4(x, x1)
        logits = self.outc(x)
        
        return torch.sigmoid(logits)  # For binary segmentation


def dice_coefficient(pred, target, smooth=1e-6):
    """
    Calculate Dice coefficient for binary segmentation.
    
    Args:
        pred: Predicted mask (batch_size, 1, H, W)
        target: Ground truth mask (batch_size, 1, H, W)
        smooth: Smoothing factor to avoid division by zero
    
    Returns:
        Dice coefficient
    """
    pred = pred.contiguous()
    target = target.contiguous()
    
    intersection = (pred * target).sum(dim=2).sum(dim=2).sum(dim=1)
    union = pred.sum(dim=2).sum(dim=2).sum(dim=1) + target.sum(dim=2).sum(dim=2).sum(dim=1)
    
    dice = (2. * intersection + smooth) / (union + smooth)
    return dice.mean()


class DiceLoss(nn.Module):
    """Dice loss for binary segmentation"""
    def __init__(self, smooth=1e-6):
        super(DiceLoss, self).__init__()
        self.smooth = smooth

    def forward(self, pred, target):
        return 1 - dice_coefficient(pred, target, self.smooth)


class CombinedLoss(nn.Module):
    """Combined BCE and Dice loss for better performance on imbalanced data"""
    def __init__(self, alpha=0.5):
        super(CombinedLoss, self).__init__()
        self.alpha = alpha
        self.bce = nn.BCELoss()
        self.dice = DiceLoss()

    def forward(self, pred, target):
        bce_loss = self.bce(pred, target)
        dice_loss = self.dice(pred, target)
        return self.alpha * bce_loss + (1 - self.alpha) * dice_loss

Train.py, training, validation and testing functions:

import torch
import torch.nn as nn
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import os
import time
import random
from tqdm import tqdm
from model import dice_coefficient

def train_epoch(model, dataloader, criterion, optimizer, device):
    """Train the model for one epoch"""
    model.train()
    running_loss = 0.0
    num_batches = len(dataloader)
    
    pbar = tqdm(dataloader, desc="Training")
    for batch_idx, (images, masks, _) in enumerate(pbar):
        images, masks = images.to(device), masks.to(device)
        
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, masks)
        loss.backward()
        optimizer.step()
        
        running_loss += loss.item()
        pbar.set_postfix({'Loss': f'{loss.item():.4f}'})
    
    return running_loss / num_batches

def validate_epoch(model, dataloader, criterion, device):
    """Validate the model for one epoch and return loss and dice scores per batch"""
    model.eval()
    running_loss = 0.0
    dice_scores = []
    
    with torch.no_grad():
        pbar = tqdm(dataloader, desc="Validation")
        for batch_idx, (images, masks, _) in enumerate(pbar):
            images, masks = images.to(device), masks.to(device)
            
            outputs = model(images)
            loss = criterion(outputs, masks)
            running_loss += loss.item()
            
            # Calculate dice score for this batch
            dice_score = dice_coefficient(outputs, masks)
            dice_scores.append(dice_score.item())
            
            pbar.set_postfix({'Loss': f'{loss.item():.4f}', 'Dice': f'{dice_score.item():.4f}'})
    
    avg_loss = running_loss / len(dataloader)
    return avg_loss, dice_scores

def test_model(model, dataloader, device, save_path):
    """Test the model and return dice scores per batch"""
    model.eval()
    dice_scores = []
    test_results = []
    
    with torch.no_grad():
        pbar = tqdm(dataloader, desc="Testing")
        for batch_idx, (images, masks, filenames) in enumerate(pbar):
            images, masks = images.to(device), masks.to(device)
            
            outputs = model(images)
            
            # Calculate dice score for this batch
            dice_score = dice_coefficient(outputs, masks)
            dice_scores.append(dice_score.item())
            
            # Store results for visualization
            for i in range(images.size(0)):
                test_results.append({
                    'image': images[i].cpu(),
                    'mask': masks[i].cpu(),
                    'prediction': outputs[i].cpu(),
                    'filename': filenames[i]
                })
            
            pbar.set_postfix({'Dice': f'{dice_score.item():.4f}'})
    
    # Save dice scores to Excel
    dice_df = pd.DataFrame([dice_scores], columns=[f'Batch_{i+1}' for i in range(len(dice_scores))])
    dice_df.to_excel(os.path.join(save_path, 'test_dice_scores.xlsx'), index=False)
    
    return dice_scores, test_results

def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, 
                num_epochs, device, save_path):
    """Complete training procedure"""
    
    print(f"Starting training for {num_epochs} epochs...")
    start_time = time.time()
    
    train_losses = []
    val_losses = []
    val_dice_scores_all = []
    
    for epoch in range(num_epochs):
        print(f"\nEpoch {epoch+1}/{num_epochs}")
        print("-" * 30)
        
        # Training
        train_loss = train_epoch(model, train_loader, criterion, optimizer, device)
        train_losses.append(train_loss)
        
        # Validation
        val_loss, val_dice_scores = validate_epoch(model, val_loader, criterion, device)
        val_losses.append(val_loss)
        val_dice_scores_all.append(val_dice_scores)
        
        # Step scheduler
        scheduler.step(val_loss)
        
        print(f"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, "
              f"Mean Val Dice: {np.mean(val_dice_scores):.4f}")
    
    # Calculate total training time
    total_time = time.time() - start_time
    print(f"\nTraining completed in {total_time:.2f} seconds ({total_time/3600:.2f} hours)")
    
    # Save losses to Excel files
    train_df = pd.DataFrame([list(range(1, num_epochs+1)), train_losses], 
                           index=['Epoch', 'Training_Loss']).T
    train_df.to_excel(os.path.join(save_path, 'train_losses.xlsx'), index=False)
    
    val_df = pd.DataFrame([list(range(1, num_epochs+1)), val_losses], 
                         index=['Epoch', 'Validation_Loss']).T
    val_df.to_excel(os.path.join(save_path, 'val_losses.xlsx'), index=False)
    
    # Save validation dice scores
    val_dice_df = pd.DataFrame(val_dice_scores_all, 
                              columns=[f'Batch_{i+1}' for i in range(len(val_dice_scores_all[0]))])
    val_dice_df.insert(0, 'Epoch', list(range(1, num_epochs+1)))
    val_dice_df.to_excel(os.path.join(save_path, 'validation_dice_scores.xlsx'), index=False)
    
    # Save model
    torch.save(model, os.path.join(save_path, 'complete_model.pth'))
    torch.save(model.state_dict(), os.path.join(save_path, 'model_state_dict.pth'))
    
    return train_losses, val_losses

def plot_losses(train_losses, val_losses, save_path):
    """Plot and save training and validation losses"""
    plt.figure(figsize=(10, 6))
    epochs = range(1, len(train_losses) + 1)
    
    plt.plot(epochs, train_losses, 'b-', label='Training Loss', linewidth=2)
    plt.plot(epochs, val_losses, 'r-', label='Validation Loss', linewidth=2)
    
    plt.title('Training and Validation Losses Over Epochs', fontsize=16)
    plt.xlabel('Epoch', fontsize=12)
    plt.ylabel('Loss', fontsize=12)
    plt.legend(fontsize=12)
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    
    plt.savefig(os.path.join(save_path, 'loss_plot.png'), dpi=300, bbox_inches='tight')
    plt.close()

def visualize_predictions(test_results, save_path, num_samples=5):
    """Visualize predictions for random test samples"""
    
    # Select random samples
    random_indices = random.sample(range(len(test_results)), min(num_samples, len(test_results)))
    selected_results = [test_results[i] for i in random_indices]
    
    fig, axes = plt.subplots(num_samples, 3, figsize=(12, 4*num_samples))
    fig.suptitle('Test Results: Input Image, Ground Truth, Prediction', fontsize=16)
    
    for i, result in enumerate(selected_results):
        image = result['image'].squeeze().numpy()
        mask = result['mask'].squeeze().numpy()
        prediction = result['prediction'].squeeze().numpy()
        filename = result['filename']
        
        # Input Image
        axes[i, 0].imshow(image, cmap='gray')
        axes[i, 0].set_title(f'Input Image\n{filename}')
        axes[i, 0].axis('off')
        
        # Ground Truth
        axes[i, 1].imshow(mask, cmap='gray')
        axes[i, 1].set_title(f'Ground Truth\n{filename}')
        axes[i, 1].axis('off')
        
        # Prediction
        axes[i, 2].imshow(prediction, cmap='gray')
        axes[i, 2].set_title(f'Prediction\n{filename}')
        axes[i, 2].axis('off')
    
    plt.tight_layout()
    plt.savefig(os.path.join(save_path, 'test_predictions.png'), dpi=300, bbox_inches='tight')
    plt.close()

Main.py, main execution script:

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Subset
from sklearn.model_selection import train_test_split
import os
import numpy as np
from torchinfo import summary

from dataset import SegmentationDataset
from model import UNet, CombinedLoss
from train import train_model, test_model, plot_losses, visualize_predictions

def main():
    # Configuration
    DATA_DIR = "path/to/your/dataset"  # Change this to your dataset path
    SAVE_PATH = "results"  # Change this to your desired save path
    MASK_SUFFIX = "_seg"  # Change this if your mask suffix is different
    
    # Hyperparameters
    BATCH_SIZE = 8
    NUM_EPOCHS = 50
    LEARNING_RATE = 1e-4
    IMAGE_SIZE = (256, 256)
    
    # Create save directory
    os.makedirs(SAVE_PATH, exist_ok=True)
    
    # Device configuration
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}")
    
    # Create dataset
    print("Loading dataset...")
    dataset = SegmentationDataset(
        image_dir=DATA_DIR,
        mask_suffix=MASK_SUFFIX,
        image_size=IMAGE_SIZE
    )
    
    # Split dataset
    total_size = len(dataset)
    indices = list(range(total_size))
    
    # First split: 80% train, 20% temp (which will be split into 10% val, 10% test)
    train_indices, temp_indices = train_test_split(
        indices, test_size=0.2, random_state=42, shuffle=True
    )
    
    # Second split: 10% val, 10% test from the 20% temp
    val_indices, test_indices = train_test_split(
        temp_indices, test_size=0.5, random_state=42, shuffle=True
    )
    
    print(f"Dataset split:")
    print(f"  Training samples: {len(train_indices)} ({len(train_indices)/total_size*100:.1f}%)")
    print(f"  Validation samples: {len(val_indices)} ({len(val_indices)/total_size*100:.1f}%)")
    print(f"  Test samples: {len(test_indices)} ({len(test_indices)/total_size*100:.1f}%)")
    
    # Create subsets
    train_dataset = Subset(dataset, train_indices)
    val_dataset = Subset(dataset, val_indices)
    test_dataset = Subset(dataset, test_indices)
    
    # Create data loaders
    train_loader = DataLoader(
        train_dataset, 
        batch_size=BATCH_SIZE, 
        shuffle=True, 
        num_workers=4, 
        pin_memory=True
    )
    
    val_loader = DataLoader(
        val_dataset, 
        batch_size=BATCH_SIZE, 
        shuffle=False, 
        num_workers=4, 
        pin_memory=True
    )
    
    test_loader = DataLoader(
        test_dataset, 
        batch_size=BATCH_SIZE, 
        shuffle=False, 
        num_workers=4, 
        pin_memory=True
    )
    
    print(f"Data loader sizes:")
    print(f"  Train batches: {len(train_loader)}")
    print(f"  Validation batches: {len(val_loader)}")
    print(f"  Test batches: {len(test_loader)}")
    
    # Initialize model
    model = UNet(n_channels=1, n_classes=1, bilinear=False).to(device)
    
    # Print model summary
    print("\nModel Summary:")
    summary(model, input_size=(1, 1, IMAGE_SIZE[0], IMAGE_SIZE[1]))
    
    # Count parameters
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"Total parameters: {total_params:,}")
    print(f"Trainable parameters: {trainable_params:,}")
    
    # Loss function and optimizer
    criterion = CombinedLoss(alpha=0.5)  # Balanced BCE and Dice loss
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', factor=0.5, patience=5, verbose=True
    )
    
    # Training
    print("\n" + "="*50)
    print("STARTING TRAINING")
    print("="*50)
    
    train_losses, val_losses = train_model(
        model=model,
        train_loader=train_loader,
        val_loader=val_loader,
        criterion=criterion,
        optimizer=optimizer,
        scheduler=scheduler,
        num_epochs=NUM_EPOCHS,
        device=device,
        save_path=SAVE_PATH
    )
    
    # Plot losses
    plot_losses(train_losses, val_losses, SAVE_PATH)
    print(f"Loss plot saved to {os.path.join(SAVE_PATH, 'loss_plot.png')}")
    
    # Testing
    print("\n" + "="*50)
    print("STARTING TESTING")
    print("="*50)
    
    test_dice_scores, test_results = test_model(
        model=model,
        dataloader=test_loader,
        device=device,
        save_path=SAVE_PATH
    )
    
    print(f"Test Results:")
    print(f"  Mean Dice Score: {np.mean(test_dice_scores):.4f}")
    print(f"  Std Dice Score: {np.std(test_dice_scores):.4f}")
    print(f"  Min Dice Score: {np.min(test_dice_scores):.4f}")
    print(f"  Max Dice Score: {np.max(test_dice_scores):.4f}")
    
    # Visualize predictions
    visualize_predictions(test_results, SAVE_PATH, num_samples=5)
    print(f"Test predictions visualization saved to {os.path.join(SAVE_PATH, 'test_predictions.png')}")
    
    print("\n" + "="*50)
    print("TRAINING AND TESTING COMPLETED")
    print("="*50)
    print(f"All results saved to: {SAVE_PATH}")
    print("Files created:")
    print("  - complete_model.pth (full model)")
    print("  - model_state_dict.pth (model weights)")
    print("  - train_losses.xlsx (training losses)")
    print("  - val_losses.xlsx (validation losses)")
    print("  - validation_dice_scores.xlsx (validation dice scores)")
    print("  - test_dice_scores.xlsx (test dice scores)")
    print("  - loss_plot.png (loss visualization)")
    print("  - test_predictions.png (prediction visualization)")

if __name__ == "__main__":
    main()

I've created a complete U-Net implementation for binary segmentation with all the requested functionality. Here's what each module contains:
dataset.py

Custom SegmentationDataset class that loads grayscale images and binary masks
Automatically finds PNG files and their corresponding masks with the specified suffix
Handles image resizing and proper transforms
Filters out non-PNG files and ensures proper pairing

model.py

Complete U-Net architecture optimized for binary segmentation
Includes DoubleConv, Down, Up, and OutConv blocks
Added dropout for regularization to prevent overfitting
Dice coefficient calculation function
Combined loss function (BCE + Dice) for better performance on imbalanced data

train.py

Training, validation, and testing functions with progress bars
Automatic saving of losses and dice scores to Excel files
Loss visualization function
Test prediction visualization for 5 random samples
Proper time tracking for total training duration

main.py

Complete execution script with proper data splitting (80/10/10)
Model summary and parameter counting using torchinfo
Hyperparameter configuration
All file saving and result reporting

Key Features Implemented:

Data Handling:

Proper train/test/validation split using train_test_split and Subset
No data duplication or copying to new directories
PNG-only file filtering with automatic mask pairing


Model Architecture:

U-Net optimized for small foreground objects
Dropout for regularization
Combined BCE and Dice loss for imbalanced data


Training Process:

Progress bars for all phases using tqdm
Automatic Excel file creation for losses and dice scores
Model saving (both complete model and state dict)
Learning rate scheduling


Visualization:

Loss plots saved as PNG
Test prediction visualization for 5 random samples
No plot display during execution (only saving)


Hyperparameters:

Appropriate settings to avoid overfitting
Small batch size (8) and learning rate (1e-4)
Weight decay for regularization



Usage:

Update the DATA_DIR and SAVE_PATH in main.py
Adjust MASK_SUFFIX if your masks have a different naming convention
Run: python main.py

The implementation is modular, complete, and ready to run with your dataset!