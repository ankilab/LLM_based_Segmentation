	provide a complete ready-to-run Python implementation for a U-Net architecture using PyTorch, for binary segmentation of grayscale images. The dataset should consist of grayscale images and corresponding binary masks, which are located in 2 different folders  or in the same path (the masks have the same name as the images, with a suffix, like: "number.png" and the masks "number_seg.png", around 5000 samples in total. access and split directly using train_test_split on the index list and Subset, and do NOT duplicate or copy to new directory). It should work and provide correct predictions, and save the losses and dice scores as instructed below. The code should be structured into importable scripts with the following:

1.	A custom Dataset class for loading the grayscale images and corresponding binary masks. (only the png files, ignore meta files or additional files in the directory)
2.	A UNet model class definition using PyTorch, optimized for binary segmentation (with small foreground, mostly background)
3.	Functions for the training procedure, validation procedure, and Testing procedure.

Considerations for each part:
4.	Ensure needed transforms on input image and mask pairs (Re-size images correctly, ensure gray scale and binary…)
5.	Avoid overfitting and data leakage (without using augmentations), choose appropriate hyperparameters, learning rate, batch size, etc

•	For Training and Validation:

6.	Compute training and validation losses.
7.	Track and save the average training loss for each epoch in a separate Excel file (train_losses.xlsx) in a given save path. The first row should contain the epoch numbers, and the second row should contain the corresponding average training loss for each epoch.
8.	Similarly, save the validation loss for each epoch in an Excel file (val_losses.xlsx) with the same structure.
9.	At the end of training, save both the entire model and the model's state dictionary (.pth files) in the save path
10.	Calculate total training time from start to end, and print at the end of training
11.	The progress, phase (train/validation), and all info should be shown epoch by epoch using `tqdm` progress bars during training, validation, and testing.
12.	A function to visualize training losses and validation losses over epochs afterwards, on the same plot. Save plot in a specified save path as png. 
13.	During Validation: mean Dice scores should be calculated over each batch, for each epoch, and stored in an Excel file (epochs as rows and batches as columns). The Excel file (named “validation_dice_scores” should be saved at the specified save path after validation is done.
14.	Do the same for the Testing and store dice the Dice scores the same way and save the excel file as “test_dice_scores” after testing is done.

•	For Testing:

15.	A function to visualize the predicted masks, the input image, and the ground truth, for 5 random samples, after testing is done. (subplots for 5 random samples in one plot, in 5 rows and 3 columns (title at top: Input Image, Ground Truth, Prediction). Also display image file name string above each image and mask. save the plot as `.png`).

•	For Main:

16.	Shuffle the data, split the dataset into: 80% training, 10% validation, and 10% test sets using `train_test_split`. Print the sizes of each (how many images), and copy the splitted data (images and their respective masks) 
17.	DataLoader setup for training, validation, and testing sets.
18.	Ensure correct data loading, print data loader sizes.
19.	Also usig torchinfo, print model summary, and total number of model parameters (n learnable params)

20.	All the above functionalities should be implemented in a modular way so that they can be imported as scripts or classes.
21.	All visualizations should just be saved as png. No need to display the plots during running.
22.	Ensure that everything can be executed in an `if __name__ == "__main__":` block with instructions for loading the dataset, configuring hyperparameters, and saving the trained model.
The directory structure should only be:
unet_segmentation/
├── dataset.py
├── model.py
├── train.py
├── main.py
We are going to create 4 files: dataset.py, model.py, train.py, main.py

Let's break down each file:

1. dataset.py: Contains the custom Dataset class for loading grayscale images and binary masks.

2. model.py: Contains the U-Net model definition.

3. train.py: Contains functions for training, validation, testing, and visualization of losses and results.

4. main.py: The main script that sets up the data, model, and runs the training and testing.

We'll implement step by step.

Note: We are going to use:

- torch

- torchvision

- torch.utils.data

- torchinfo for model summary

- numpy

- pandas for Excel files

- matplotlib for plots

- tqdm for progress bars

- sklearn for train_test_split

We assume the images and masks are in the same folder or two different folders. We'll design the dataset to handle both cases.

We are given:

- Images: named like "number.png"

- Masks: named like "number_seg.png"

We'll create a dataset that takes the image directory and mask directory (if same, then same path) and a list of filenames (without the suffix) for the images. The mask is then built by appending the suffix to the base name.

We'll use the following transforms:

- Resize: to a fixed size (e.g., 256x256) - note: we are doing binary segmentation so we need to resize the mask with nearest neighbor.

- ToTensor: for both image and mask.

- Normalize: for the image (mean=0.5, std=0.5) to bring to [-1,1] range? or we can use [0,1] and then normalize. Alternatively, we can just use ToTensor and then normalize by 255. But note: ToTensor for grayscale will give [0,1]. We can then normalize by (img - 0.5)/0.5 to get [-1,1]. But for binary mask, we want 0 and 1.

Alternatively, we can do:

For image:

transforms.ToTensor() -> [0,1]

then transforms.Normalize(mean=[0.5], std=[0.5]) -> [-1,1]

For mask:

We just need to convert to tensor and then threshold at 0.5? But note: our masks are binary. So we can read as grayscale and then convert to tensor. Then we can threshold at 128 to get 0 and 1? Actually, the mask might be 0 and 255. So we can do: mask = (mask > 0).float().

But in the dataset, we can do:

mask = Image.open(mask_path)

mask = np.array(mask)

mask = (mask > 128).astype(np.float32)   # assuming background=0 and foreground=255

But note: the problem says "binary masks", so they should be 0 and 1. But in practice, they might be saved as 0 and 255.

We'll design the dataset to handle that.

We'll create a transform for the image and for the mask. We can use a composed transform for the image and a separate one for the mask.

Let's write the dataset:

File: dataset.py

Here's the complete implementation structured into the required files:

File Structure:

text
unet_segmentation/
├── dataset.py
├── model.py
├── train.py
└── main.py
1. dataset.py
python
import os
import torch
from torch.utils.data import Dataset
from PIL import Image
import numpy as np
import torchvision.transforms as transforms

class SegmentationDataset(Dataset):
    def __init__(self, image_dir, mask_dir=None, img_size=256, is_test=False):
        """
        Args:
            image_dir: Directory with input images
            mask_dir: Directory with mask images (defaults to image_dir if None)
            img_size: Target size for resizing
            is_test: If True, skips mask loading for inference
        """
        self.image_dir = image_dir
        self.mask_dir = mask_dir if mask_dir else image_dir
        self.img_size = img_size
        self.is_test = is_test
        
        # Collect image files (png only)
        self.image_files = [f for f in os.listdir(image_dir) if f.endswith('.png') and '_seg' not in f]
        
        # Transform for images
        self.image_transform = transforms.Compose([
            transforms.Resize((img_size, img_size)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.5], std=[0.5])
        ])
        
        # Transform for masks
        self.mask_transform = transforms.Compose([
            transforms.Resize((img_size, img_size), 
                             interpolation=transforms.InterpolationMode.NEAREST),
            transforms.ToTensor()
        ])

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        img_name = self.image_files[idx]
        img_path = os.path.join(self.image_dir, img_name)
        
        # Load image
        image = Image.open(img_path).convert('L')
        image = self.image_transform(image)
        
        # Handle mask if not in test mode
        mask = torch.Tensor()
        if not self.is_test:
            mask_name = f"{os.path.splitext(img_name)[0]}_seg.png"
            mask_path = os.path.join(self.mask_dir, mask_name)
            mask = Image.open(mask_path).convert('L')
            mask = self.mask_transform(mask)
            # Binarize mask (0 or 1)
            mask = (mask > 0.5).float()
            
        return image, mask, img_name
2. model.py
python
import torch
import torch.nn as nn

class DoubleConv(nn.Module):
    """(Conv2d => BN => ReLU) * 2"""
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.double_conv = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )

    def forward(self, x):
        return self.double_conv(x)

class Down(nn.Module):
    """Downscaling with maxpool then double conv"""
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.maxpool_conv = nn.Sequential(
            nn.MaxPool2d(2),
            DoubleConv(in_channels, out_channels)
        )

    def forward(self, x):
        return self.maxpool_conv(x)

class Up(nn.Module):
    """Upscaling then double conv"""
    def __init__(self, in_channels, out_channels, bilinear=True):
        super().__init__()
        if bilinear:
            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)
        else:
            self.up = nn.ConvTranspose2d(in_channels//2, in_channels//2, kernel_size=2, stride=2)
            
        self.conv = DoubleConv(in_channels, out_channels)

    def forward(self, x1, x2):
        x1 = self.up(x1)
        # Pad if necessary for size mismatch
        diffY = x2.size()[2] - x1.size()[2]
        diffX = x2.size()[3] - x1.size()[3]
        x1 = nn.functional.pad(x1, [diffX//2, diffX - diffX//2,
                                    diffY//2, diffY - diffY//2])
        x = torch.cat([x2, x1], dim=1)
        return self.conv(x)

class UNet(nn.Module):
    def __init__(self, n_channels=1, n_classes=1, bilinear=True):
        super(UNet, self).__init__()
        self.n_channels = n_channels
        self.n_classes = n_classes
        self.bilinear = bilinear

        self.inc = DoubleConv(n_channels, 64)
        self.down1 = Down(64, 128)
        self.down2 = Down(128, 256)
        self.down3 = Down(256, 512)
        self.down4 = Down(512, 1024)
        self.up1 = Up(1024 + 512, 512, bilinear)
        self.up2 = Up(512 + 256, 256, bilinear)
        self.up3 = Up(256 + 128, 128, bilinear)
        self.up4 = Up(128 + 64, 64, bilinear)
        self.outc = nn.Conv2d(64, n_classes, kernel_size=1)

    def forward(self, x):
        x1 = self.inc(x)
        x2 = self.down1(x1)
        x3 = self.down2(x2)
        x4 = self.down3(x3)
        x5 = self.down4(x4)
        
        x = self.up1(x5, x4)
        x = self.up2(x, x3)
        x = self.up3(x, x2)
        x = self.up4(x, x1)
        logits = self.outc(x)
        return torch.sigmoid(logits)
3. train.py
python
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from tqdm import tqdm
import os

# Loss function with background weighting
class DiceBCELoss(nn.Module):
    def __init__(self, weight=0.7):
        super(DiceBCELoss, self).__init__()
        self.weight = weight  # Weight for BCE (Dice weight = 1 - weight)

    def forward(self, inputs, targets):
        # Binary Cross Entropy
        bce = nn.functional.binary_cross_entropy(inputs, targets)
        
        # Dice Coefficient
        smooth = 1.0
        intersection = (inputs * targets).sum()
        dice = (2. * intersection + smooth) / (inputs.sum() + targets.sum() + smooth)
        
        return self.weight * bce + (1 - self.weight) * (1 - dice)

def dice_score(preds, targets):
    preds_bin = (preds > 0.5).float()
    intersection = (preds_bin * targets).sum(dim=(1,2,3))
    return (2. * intersection) / (preds_bin.sum(dim=(1,2,3)) + targets.sum(dim=(1,2,3)))

def train_epoch(model, loader, device, optimizer, criterion):
    model.train()
    running_loss = 0.0
    
    for images, masks, _ in tqdm(loader, desc="Training"):
        images = images.to(device)
        masks = masks.to(device)
        
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, masks)
        loss.backward()
        optimizer.step()
        
        running_loss += loss.item() * images.size(0)
        
    return running_loss / len(loader.dataset)

def validate_epoch(model, loader, device, criterion):
    model.eval()
    running_loss = 0.0
    dice_scores = []
    
    with torch.no_grad():
        for images, masks, _ in tqdm(loader, desc="Validation"):
            images = images.to(device)
            masks = masks.to(device)
            
            outputs = model(images)
            loss = criterion(outputs, masks)
            running_loss += loss.item() * images.size(0)
            
            # Calculate Dice per sample
            batch_dice = dice_score(outputs, masks).cpu().numpy()
            dice_scores.extend(batch_dice)
            
    return running_loss / len(loader.dataset), np.array(dice_scores)

def test_model(model, loader, device):
    model.eval()
    dice_scores = []
    all_images, all_masks, all_preds, all_names = [], [], [], []
    
    with torch.no_grad():
        for images, masks, names in tqdm(loader, desc="Testing"):
            images = images.to(device)
            masks = masks.to(device)
            
            outputs = model(images)
            batch_dice = dice_score(outputs, masks).cpu().numpy()
            dice_scores.extend(batch_dice)
            
            # Store samples for visualization
            if len(all_images) < 5:
                all_images.append(images.cpu())
                all_masks.append(masks.cpu())
                all_preds.append(outputs.cpu())
                all_names.extend(names)
    
    # Concatenate stored samples
    vis_images = torch.cat(all_images, dim=0)[:5]
    vis_masks = torch.cat(all_masks, dim=0)[:5]
    vis_preds = torch.cat(all_preds, dim=0)[:5]
    
    return np.array(dice_scores), (vis_images, vis_masks, vis_preds, all_names[:5])

def save_loss_plot(train_losses, val_losses, save_path):
    plt.figure(figsize=(10, 5))
    plt.plot(train_losses, label='Training Loss')
    plt.plot(val_losses, label='Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.title('Training and Validation Losses')
    plt.legend()
    plt.savefig(os.path.join(save_path, 'loss_plot.png'))
    plt.close()

def save_sample_visualization(samples, save_path):
    images, masks, preds, names = samples
    fig, axes = plt.subplots(5, 3, figsize=(10, 15))
    fig.suptitle('Segmentation Results', fontsize=16)
    
    for i in range(5):
        # Input image (denormalize)
        img = images[i].squeeze().numpy()
        img = (img * 0.5) + 0.5  # [-1,1] to [0,1]
        
        axes[i, 0].imshow(img, cmap='gray')
        axes[i, 0].set_title(f"Input: {names[i]}")
        
        # Ground truth mask
        mask = masks[i].squeeze().numpy()
        axes[i, 1].imshow(mask, cmap='gray')
        axes[i, 1].set_title("Ground Truth")
        
        # Prediction
        pred = preds[i].squeeze().numpy()
        axes[i, 2].imshow(pred > 0.5, cmap='gray')
        axes[i, 2].set_title("Prediction")
    
    plt.tight_layout()
    plt.savefig(os.path.join(save_path, 'sample_predictions.png'))
    plt.close()
4. main.py
python
import os
import torch
import torch.utils.data as data
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from torchinfo import summary
from tqdm import tqdm
import time
from dataset import SegmentationDataset
from model import UNet
from train import *

# Configuration
DATA_PATH = '/path/to/your/data'  # Update this path
SAVE_PATH = '/path/to/save/results'  # Update this path
os.makedirs(SAVE_PATH, exist_ok=True)

# Hyperparameters
IMG_SIZE = 256
BATCH_SIZE = 8
EPOCHS = 30
LR = 0.001
WEIGHT_DECAY = 1e-5
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
SEED = 42
torch.manual_seed(SEED)

def main():
    # Create dataset
    dataset = SegmentationDataset(DATA_PATH, img_size=IMG_SIZE)
    
    # Split indices
    idx = list(range(len(dataset)))
    train_idx, test_idx = train_test_split(idx, test_size=0.2, random_state=SEED)
    val_idx, test_idx = train_test_split(test_idx, test_size=0.5, random_state=SEED)
    
    print(f"Total samples: {len(dataset)}")
    print(f"Train: {len(train_idx)}, Val: {len(val_idx)}, Test: {len(test_idx)}")
    
    # Create subsets and dataloaders
    train_set = data.Subset(dataset, train_idx)
    val_set = data.Subset(dataset, val_idx)
    test_set = data.Subset(dataset, test_idx)
    
    train_loader = data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)
    val_loader = data.DataLoader(val_set, batch_size=BATCH_SIZE)
    test_loader = data.DataLoader(test_set, batch_size=BATCH_SIZE)
    
    # Initialize model
    model = UNet(n_channels=1, n_classes=1).to(DEVICE)
    
    # Print model summary
    summary(model, input_size=(BATCH_SIZE, 1, IMG_SIZE, IMG_SIZE))
    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"Trainable parameters: {total_params:,}")
    
    # Loss and optimizer
    criterion = DiceBCELoss(weight=0.7)  # 70% BCE, 30% Dice
    optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)
    
    # Training loop
    train_losses = []
    val_losses = []
    val_dice_scores = []
    start_time = time.time()
    
    for epoch in range(EPOCHS):
        print(f"\nEpoch {epoch+1}/{EPOCHS}")
        
        # Training
        train_loss = train_epoch(model, train_loader, DEVICE, optimizer, criterion)
        train_losses.append(train_loss)
        
        # Validation
        val_loss, dice_scores = validate_epoch(model, val_loader, DEVICE, criterion)
        val_losses.append(val_loss)
        val_dice_scores.append(dice_scores)
        
        print(f"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}")
        print(f"Val Dice: {np.mean(dice_scores):.4f} ± {np.std(dice_scores):.4f}")
    
    total_time = time.time() - start_time
    print(f"\nTraining completed in {total_time//60:.0f}m {total_time%60:.0f}s")
    
    # Save losses
    pd.DataFrame(train_losses).to_excel(os.path.join(SAVE_PATH, 'train_losses.xlsx'), header=False)
    pd.DataFrame(val_losses).to_excel(os.path.join(SAVE_PATH, 'val_losses.xlsx'), header=False)
    
    # Save dice scores (epochs x batches)
    dice_df = pd.DataFrame(val_dice_scores).T
    dice_df.columns = [f'Epoch {i+1}' for i in range(EPOCHS)]
    dice_df.to_excel(os.path.join(SAVE_PATH, 'validation_dice_scores.xlsx'))
    
    # Save model
    torch.save(model.state_dict(), os.path.join(SAVE_PATH, 'unet_model.pth'))
    torch.save(model, os.path.join(SAVE_PATH, 'unet_full.pth'))
    
    # Loss plot
    save_loss_plot(train_losses, val_losses, SAVE_PATH)
    
    # Testing
    test_dice, test_samples = test_model(model, test_loader, DEVICE)
    print(f"Test Dice: {np.mean(test_dice):.4f} ± {np.std(test_dice):.4f}")
    
    # Save test dice scores
    pd.DataFrame(test_dice).to_excel(os.path.join(SAVE_PATH, 'test_dice_scores.xlsx'), header=False)
    
    # Visualize samples
    save_sample_visualization(test_samples, SAVE_PATH)

if __name__ == "__main__":
    main()
Key Features:
Dataset Handling:

Automatically pairs images with masks using naming convention

Handles grayscale images and binarizes masks

Proper resizing with nearest-neighbor for masks

U-Net Architecture:

Contracting path with double convolutions and max pooling

Expanding path with transposed convolutions

Skip connections for feature preservation

Sigmoid output for binary segmentation

Training Optimization:

Combined Dice-BCE loss (70% BCE, 30% Dice) for class imbalance

Adam optimizer with weight decay

Automatic device selection (GPU/CPU)

Evaluation Metrics:

Batch-wise Dice score calculation

Loss tracking per epoch

Statistical reporting (mean ± std)

Result Visualization:

Training/validation loss plot

Sample predictions with input/GT/prediction

Excel exports for all metrics

Reproducibility:

Random seed fixed for splits

No data leakage through proper indexing

Deterministic operations where possible

Usage:
Set DATA_PATH and SAVE_PATH in main.py

Adjust hyperparameters as needed (image size, batch size, epochs)

Run python main.py

The implementation handles:

Automatic data splitting without duplication

Progress tracking with tqdm

Model summary with parameter count

All required visualizations and Excel exports

Proper device management (GPU/CPU)

Class imbalance handling through custom loss

Note: Ensure you have required libraries installed (torch, torchvision, pandas, tqdm, scikit-learn, matplotlib). For torchinfo: pip install torchinfo