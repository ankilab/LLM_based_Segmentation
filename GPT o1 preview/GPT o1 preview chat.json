Please provide a complete ready-to-run Python implementation for a U-Net architecture using PyTorch, for binary segmentation of grayscale images. The dataset should consist of grayscale images and corresponding binary masks, which are located in the same path (the images are named with numbering like "number.png" and the masks "number_seg.png", around 5000 samples in total). It should work and provide correct predictions, and save the losses and dice scores as instructed below. The code should be structured into importable scripts with the following: 

1.	A custom Dataset class for loading the grayscale images and corresponding binary masks. (only the png files, ignore meta files or additional files in the directory)
2.	A UNet model class definition using PyTorch, optimized for binary segmentation (with small foreground, mostly background)
3.	Functions for the training procedure, validation procedure, and Testing procedure.

Considerations for each part:
4.	Ensure needed transforms on input image and mask pairs (Re-size images correctly, ensure gray scale and binary…)
5.	Avoid overfitting and data leakage (without using augmentations), choose appropriate hyperparameters, learning rate, batch size, etc

•	For Training and Validation:

6.	Compute training and validation losses.
7.	Track and save the average training loss for each epoch in a separate Excel file (train_losses.xlsx) in a given save path. The first row should contain the epoch numbers, and the second row should contain the corresponding average training loss for each epoch.
8.	Similarly, save the validation loss for each epoch in an Excel file (val_losses.xlsx) with the same structure.
9.	At the end of training, save both the entire model and the model's state dictionary (.pth files) in the save path
10.	Calculate total training time from start to end, and print at the end of training
11.	The progress, phase (train/validation), and all info should be shown epoch by epoch using tqdm progress bars during training, validation, and testing.
12.	A function to visualize training losses and validation losses over epochs afterwards, on the same plot. Save plot in a specified save path as png. 
13.	During Validation: Dice scores should be calculated for each batch, and all dice coefficients for the entire epoch should be stored in an Excel file, where each row in the Excel file should represent an epoch, and each column should represent a batch. The Excel file (named “validation_dice_scores” should be saved at the specified save path after validation is done.
14.	Do the same for the Testing and store dice the Dice scores the same way and save the excel file as “test_dice_scores” after testing is done.

•	For Testing:

15.	A function to visualize the predicted masks, the input image, and the ground truth, for 5 random samples, after testing is done. (subplots for 5 random samples in one plot, in 5 rows and 3 columns (title at top: Input Image, Ground Truth, Prediction). Also display image file name /id string above each image and mask. save the plot as .png).

•	For Main:

16.	Shuffle the data, split the dataset into: 80% training, 10% validation, and 10% test sets using train_test_split. Print the sizes of each (how many images), and copy the splitted data (images and their respective masks) 
17.	DataLoader setup for training, validation, and testing sets.
18.	Ensure correct data loading, print data loader sizes.
19.	Also print model summary, and total number of model parameters (n learnable params)

20.	All the above functionalities should be implemented in a modular way so that they can be imported as scripts or classes.
21.	All visualizations should just be saved as png. No need to display the plots during running.
22.	Ensure that everything can be executed in an if __name__ == "__main__": block with instructions for loading the dataset, configuring hyperparameters, and saving the trained model.
The directory structure should only be:
unet_segmentation/
├── dataset.py
├── model.py
├── train.py
├── main.py

ChatGPT

Thought for 72 seconds

Here's the complete Python implementation structured as per your requirements:

Directory Structure:

css
Copy code
unet_segmentation/
├── dataset.py
├── model.py
├── train.py
└── main.py
dataset.py
python
Copy code
# dataset.py
import os
from torch.utils.data import Dataset
from PIL import Image
import torch
from torchvision import transforms
from torchvision.transforms import functional as TF

class CustomSegmentationDataset(Dataset):
    def __init__(self, image_dir, mask_dir, image_size=(256, 256), transform=None):
        self.image_dir = image_dir  # Path to images
        self.mask_dir = mask_dir    # Path to masks
        self.transform = transform
        self.image_size = image_size
        self.images = [img for img in os.listdir(image_dir) if img.endswith('.png') and not img.endswith('_seg.png')]
        self.images.sort()

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        img_name = self.images[idx]
        mask_name = img_name.replace('.png', '_seg.png')

        img_path = os.path.join(self.image_dir, img_name)
        mask_path = os.path.join(self.mask_dir, mask_name)

        image = Image.open(img_path).convert('L')  # Convert to grayscale
        mask = Image.open(mask_path).convert('L')  # Convert to grayscale

        # Resize images and masks
        resize = transforms.Resize(self.image_size)
        image = resize(image)
        mask = resize(mask)

        # Apply any transforms if provided
        if self.transform:
            image, mask = self.transform(image, mask)

        # Convert images to tensors
        image = TF.to_tensor(image)
        mask = TF.to_tensor(mask)
        mask = (mask > 0.5).float()  # Binarize mask

        return image, mask, img_name
model.py
python
Copy code
# model.py
import torch
import torch.nn as nn

class UNet(nn.Module):
    def __init__(self):
        super(UNet, self).__init__()

        # Contracting path
        self.conv1 = self.double_conv(1, 64)
        self.pool1 = nn.MaxPool2d(2)

        self.conv2 = self.double_conv(64, 128)
        self.pool2 = nn.MaxPool2d(2)

        self.conv3 = self.double_conv(128, 256)
        self.pool3 = nn.MaxPool2d(2)

        self.conv4 = self.double_conv(256, 512)
        self.pool4 = nn.MaxPool2d(2)

        self.conv5 = self.double_conv(512, 1024)

        # Expanding path
        self.up6 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)
        self.conv6 = self.double_conv(1024, 512)

        self.up7 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)
        self.conv7 = self.double_conv(512, 256)

        self.up8 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)
        self.conv8 = self.double_conv(256, 128)

        self.up9 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)
        self.conv9 = self.double_conv(128, 64)

        self.conv10 = nn.Conv2d(64, 1, kernel_size=1)
        self.sigmoid = nn.Sigmoid()

    def double_conv(self, in_channels, out_channels):
        conv = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, 3, padding=1),
            nn.BatchNorm2d(out_channels),  # Added BatchNorm
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, 3, padding=1),
            nn.BatchNorm2d(out_channels),  # Added BatchNorm
            nn.ReLU(inplace=True)
        )
        return conv

    def forward(self, x):
        # Contracting path
        c1 = self.conv1(x)
        p1 = self.pool1(c1)

        c2 = self.conv2(p1)
        p2 = self.pool2(c2)

        c3 = self.conv3(p2)
        p3 = self.pool3(c3)

        c4 = self.conv4(p3)
        p4 = self.pool4(c4)

        c5 = self.conv5(p4)

        # Expanding path
        u6 = self.up6(c5)
        u6 = torch.cat([u6, c4], dim=1)
        c6 = self.conv6(u6)

        u7 = self.up7(c6)
        u7 = torch.cat([u7, c3], dim=1)
        c7 = self.conv7(u7)

        u8 = self.up8(c7)
        u8 = torch.cat([u8, c2], dim=1)
        c8 = self.conv8(u8)

        u9 = self.up9(c8)
        u9 = torch.cat([u9, c1], dim=1)
        c9 = self.conv9(u9)

        c10 = self.conv10(c9)
        output = self.sigmoid(c10)

        return output
train.py
python
Copy code
# train.py
import torch
import torch.nn as nn
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import random
import os
from tqdm import tqdm

def dice_coefficient(preds, targets, smooth=1e-6):
    preds = preds.view(-1)
    targets = targets.view(-1)
    intersection = (preds * targets).sum()
    dice = (2. * intersection + smooth) / (preds.sum() + targets.sum() + smooth)
    return dice

def train_model(model, dataloader, criterion, optimizer, device):
    model.train()
    running_loss = 0.0
    loop = tqdm(dataloader, leave=False)
    for inputs, masks, _ in loop:
        inputs = inputs.to(device)
        masks = masks.to(device)

        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, masks)
        loss.backward()
        optimizer.step()

        running_loss += loss.item() * inputs.size(0)

        loop.set_postfix({'loss': loss.item()})

    epoch_loss = running_loss / len(dataloader.dataset)
    return epoch_loss

def validate_model(model, dataloader, criterion, device, epoch_num, save_path):
    model.eval()
    running_loss = 0.0
    dice_scores = []
    loop = tqdm(dataloader, leave=False)
    with torch.no_grad():
        for inputs, masks, _ in loop:
            inputs = inputs.to(device)
            masks = masks.to(device)

            outputs = model(inputs)
            loss = criterion(outputs, masks)
            running_loss += loss.item() * inputs.size(0)

            # Calculate Dice score per batch
            preds = (outputs > 0.5).float()
            dice = dice_coefficient(preds, masks)
            dice_scores.append(dice.item())

            loop.set_postfix({'loss': loss.item(), 'dice': dice.item()})

    epoch_loss = running_loss / len(dataloader.dataset)

    # Save dice scores to Excel
    df = pd.DataFrame([dice_scores])
    excel_path = os.path.join(save_path, 'validation_dice_scores.xlsx')
    if not os.path.exists(excel_path):
        df.to_excel(excel_path, index=False, header=False)
    else:
        with pd.ExcelWriter(excel_path, mode='a', engine='openpyxl') as writer:
            df.to_excel(writer, index=False, header=False, startrow=epoch_num)

    return epoch_loss

def test_model(model, dataloader, device, save_path):
    model.eval()
    dice_scores = []
    all_inputs = []
    all_masks = []
    all_preds = []
    all_img_names = []
    loop = tqdm(dataloader, leave=False)
    with torch.no_grad():
        for inputs, masks, img_names in loop:
            inputs = inputs.to(device)
            masks = masks.to(device)

            outputs = model(inputs)

            preds = (outputs > 0.5).float()
            dice = dice_coefficient(preds, masks)
            dice_scores.append(dice.item())

            loop.set_postfix({'dice': dice.item()})

            all_inputs.extend(inputs.cpu())
            all_masks.extend(masks.cpu())
            all_preds.extend(preds.cpu())
            all_img_names.extend(img_names)

    # Save dice scores to Excel
    df = pd.DataFrame([dice_scores])
    df.to_excel(os.path.join(save_path, 'test_dice_scores.xlsx'), index=False, header=False)

    return all_inputs, all_masks, all_preds, all_img_names

def save_losses_to_excel(train_losses, val_losses, save_path):
    epochs = list(range(1, len(train_losses) + 1))

    # Train losses
    df_train = pd.DataFrame([epochs, train_losses])
    df_train.to_excel(os.path.join(save_path, 'train_losses.xlsx'), index=False, header=False)

    # Validation losses
    df_val = pd.DataFrame([epochs, val_losses])
    df_val.to_excel(os.path.join(save_path, 'val_losses.xlsx'), index=False, header=False)

def plot_losses(train_losses, val_losses, save_path):
    epochs = list(range(1, len(train_losses) + 1))
    plt.figure()
    plt.plot(epochs, train_losses, 'b', label='Training loss')
    plt.plot(epochs, val_losses, 'r', label='Validation loss')
    plt.title('Training and Validation losses')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.savefig(os.path.join(save_path, 'losses.png'))
    plt.close()

def visualize_predictions(inputs, masks, preds, img_names, save_path):
    indices = random.sample(range(len(inputs)), 5)
    fig, axs = plt.subplots(5, 3, figsize=(12, 20))
    for i, idx in enumerate(indices):
        input_img = inputs[idx][0]  # Get the first channel
        mask_img = masks[idx][0]
        pred_img = preds[idx][0]
        img_name = img_names[idx]

        axs[i, 0].imshow(input_img, cmap='gray')
        axs[i, 0].set_title(f"Input Image: {img_name}")
        axs[i, 0].axis('off')

        axs[i, 1].imshow(mask_img, cmap='gray')
        axs[i, 1].set_title("Ground Truth")
        axs[i, 1].axis('off')

        axs[i, 2].imshow(pred_img, cmap='gray')
        axs[i, 2].set_title("Prediction")
        axs[i, 2].axis('off')
    plt.tight_layout()
    plt.savefig(os.path.join(save_path, 'test_predictions.png'))
    plt.close()
main.py
python
Copy code
# main.py
import os
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from sklearn.model_selection import train_test_split
from dataset import CustomSegmentationDataset
from model import UNet
from train import train_model, validate_model, test_model, save_losses_to_excel, plot_losses, visualize_predictions
from torchsummary import summary
import time
import shutil
from tqdm import tqdm

if __name__ == "__main__":
    # Paths
    dataset_path = '/path/to/dataset'  # Replace with your dataset path
    image_dir = dataset_path
    mask_dir = dataset_path

    # Save path for outputs
    save_path = '/path/to/save_directory'  # Replace with your save directory
    if not os.path.exists(save_path):
        os.makedirs(save_path)

    # Get list of image files
    images = [img for img in os.listdir(image_dir) if img.endswith('.png') and not img.endswith('_seg.png')]
    images.sort()

    # Shuffle and split the data
    train_imgs, val_test_imgs = train_test_split(images, test_size=0.2, random_state=42, shuffle=True)
    val_imgs, test_imgs = train_test_split(val_test_imgs, test_size=0.5, random_state=42, shuffle=True)

    # Print sizes
    print(f"Total images: {len(images)}")
    print(f"Training images: {len(train_imgs)}")
    print(f"Validation images: {len(val_imgs)}")
    print(f"Test images: {len(test_imgs)}")

    # Create directories for splits
    split_dirs = ['train', 'val', 'test']
    for split_dir in split_dirs:
        img_split_dir = os.path.join(save_path, split_dir, 'images')
        mask_split_dir = os.path.join(save_path, split_dir, 'masks')
        os.makedirs(img_split_dir, exist_ok=True)
        os.makedirs(mask_split_dir, exist_ok=True)

    # Copy files
    def copy_files(file_list, split):
        img_dest = os.path.join(save_path, split, 'images')
        mask_dest = os.path.join(save_path, split, 'masks')
        for img_name in tqdm(file_list, desc=f"Copying {split} data"):
            mask_name = img_name.replace('.png', '_seg.png')
            shutil.copy(os.path.join(image_dir, img_name), os.path.join(img_dest, img_name))
            shutil.copy(os.path.join(mask_dir, mask_name), os.path.join(mask_dest, mask_name))

    copy_files(train_imgs, 'train')
    copy_files(val_imgs, 'val')
    copy_files(test_imgs, 'test')

    # Hyperparameters
    image_size = (256, 256)
    batch_size = 16
    num_epochs = 10
    learning_rate = 1e-4

    # Datasets
    train_dataset = CustomSegmentationDataset(
        image_dir=os.path.join(save_path, 'train', 'images'),
        mask_dir=os.path.join(save_path, 'train', 'masks'),
        image_size=image_size
    )

    val_dataset = CustomSegmentationDataset(
        image_dir=os.path.join(save_path, 'val', 'images'),
        mask_dir=os.path.join(save_path, 'val', 'masks'),
        image_size=image_size
    )

    test_dataset = CustomSegmentationDataset(
        image_dir=os.path.join(save_path, 'test', 'images'),
        mask_dir=os.path.join(save_path, 'test', 'masks'),
        image_size=image_size
    )

    # Dataloaders
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

    print(f"Train DataLoader size: {len(train_loader)}")
    print(f"Validation DataLoader size: {len(val_loader)}")
    print(f"Test DataLoader size: {len(test_loader)}")

    # Model, criterion, optimizer
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = UNet().to(device)
    criterion = nn.BCELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

    # Print model summary and total parameters
    summary(model, input_size=(1, image_size[0], image_size[1]))
    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"Total number of trainable parameters: {total_params}")

    # Training
    train_losses = []
    val_losses = []

    start_time = time.time()

    for epoch in range(num_epochs):
        print(f"Epoch {epoch+1}/{num_epochs}")

        train_loss = train_model(model, train_loader, criterion, optimizer, device)
        val_loss = validate_model(model, val_loader, criterion, device, epoch, save_path)

        train_losses.append(train_loss)
        val_losses.append(val_loss)

        print(f"Training Loss: {train_loss:.4f}")
        print(f"Validation Loss: {val_loss:.4f}")

    total_time = time.time() - start_time
    print(f"Total training time: {total_time:.2f} seconds")

    # Save the model
    torch.save(model, os.path.join(save_path, 'unet_model.pth'))
    torch.save(model.state_dict(), os.path.join(save_path, 'unet_model_state_dict.pth'))

    # Save losses to Excel files
    save_losses_to_excel(train_losses, val_losses, save_path)

    # Plot losses
    plot_losses(train_losses, val_losses, save_path)

    # Testing
    all_inputs, all_masks, all_preds, all_img_names = test_model(model, test_loader, device, save_path)

    # Visualize predictions
    visualize_predictions(all_inputs, all_masks, all_preds, all_img_names, save_path)
Instructions:

Replace '/path/to/dataset' with the path to your dataset containing the images and masks.
Replace '/path/to/save_directory' with the path where you want to save outputs like models, plots, and Excel files.
Adjust image_size, batch_size, num_epochs, and learning_rate as needed.
Run main.py to execute the entire pipeline.
Notes:

The code handles the data splitting and copies the respective images and masks to separate directories for training, validation, and testing.
Training and validation losses are saved in Excel files (train_losses.xlsx and val_losses.xlsx) with epochs in the first row and losses in the second row.
Dice scores for validation and testing are saved in validation_dice_scores.xlsx and test_dice_scores.xlsx, with each row representing an epoch and each column representing a batch.
Model summary and the total number of trainable parameters are printed.
All progress bars and epoch information are displayed using tqdm.
Visualizations are saved as .png files in the specified save path.
Please ensure all dependencies like torch, torchvision, numpy, pandas, matplotlib, tqdm, and torchsummary are installed before running the scripts.






You said:
Epoch 2/3
Traceback (most recent call last):
  File "D:\qy44lyfe\LLM segmentation\github repo\LLM_based_Segmentation\GPT o1 preview\main.py", line 116, in <module>
    val_loss = validate_model(model, val_loader, criterion, device, epoch, save_path)
  File "D:\qy44lyfe\LLM segmentation\github repo\LLM_based_Segmentation\GPT o1 preview\train.py", line 69, in validate_model
    df.to_excel(writer, index=False, header=False, startrow=epoch_num)
  File "C:\Users\qy44lyfe\.conda\envs\Swallowenv\lib\site-packages\pandas\util\_decorators.py", line 333, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\qy44lyfe\.conda\envs\Swallowenv\lib\site-packages\pandas\core\generic.py", line 2414, in to_excel
    formatter.write(
  File "C:\Users\qy44lyfe\.conda\envs\Swallowenv\lib\site-packages\pandas\io\formats\excel.py", line 952, in write
    writer._write_cells(
  File "C:\Users\qy44lyfe\.conda\envs\Swallowenv\lib\site-packages\pandas\io\excel\_openpyxl.py", line 463, in _write_cells
    raise ValueError(
ValueError: Sheet 'Sheet1' already exists and if_sheet_exists is set to 'error'.

Process finished with exit code 1
ChatGPT

Thought for 36 seconds

I apologize for the inconvenience you're experiencing. The error occurs because when writing to an existing Excel file with pandas.ExcelWriter in append mode, pandas requires you to handle existing sheets properly. Let's fix this issue by modifying the validate_model and test_model functions to correctly append data to the Excel files.

Here's the corrected code:

train.py (Corrected)
python
Copy code
# train.py
import torch
import torch.nn as nn
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import random
import os
from tqdm import tqdm

def dice_coefficient(preds, targets, smooth=1e-6):
    preds = preds.view(-1)
    targets = targets.view(-1)
    intersection = (preds * targets).sum()
    dice = (2. * intersection + smooth) / (preds.sum() + targets.sum() + smooth)
    return dice

def train_model(model, dataloader, criterion, optimizer, device):
    model.train()
    running_loss = 0.0
    loop = tqdm(dataloader, leave=False, desc='Training')
    for inputs, masks, _ in loop:
        inputs = inputs.to(device)
        masks = masks.to(device)

        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, masks)
        loss.backward()
        optimizer.step()

        running_loss += loss.item() * inputs.size(0)

        loop.set_postfix({'loss': loss.item()})

    epoch_loss = running_loss / len(dataloader.dataset)
    return epoch_loss

def validate_model(model, dataloader, criterion, device, epoch_num, save_path):
    model.eval()
    running_loss = 0.0
    dice_scores = []
    loop = tqdm(dataloader, leave=False, desc='Validation')
    with torch.no_grad():
        for inputs, masks, _ in loop:
            inputs = inputs.to(device)
            masks = masks.to(device)

            outputs = model(inputs)
            loss = criterion(outputs, masks)
            running_loss += loss.item() * inputs.size(0)

            # Calculate Dice score per batch
            preds = (outputs > 0.5).float()
            dice = dice_coefficient(preds, masks)
            dice_scores.append(dice.item())

            loop.set_postfix({'loss': loss.item(), 'dice': dice.item()})

    epoch_loss = running_loss / len(dataloader.dataset)

    # Save dice scores to Excel
    df_new = pd.DataFrame([dice_scores])
    excel_path = os.path.join(save_path, 'validation_dice_scores.xlsx')
    if not os.path.exists(excel_path):
        df_new.to_excel(excel_path, index=False, header=False)
    else:
        # Read existing data
        df_existing = pd.read_excel(excel_path, header=None)
        # Append new data
        df_combined = pd.concat([df_existing, df_new], ignore_index=True)
        # Write back to Excel
        df_combined.to_excel(excel_path, index=False, header=False)

    return epoch_loss

def test_model(model, dataloader, device, save_path):
    model.eval()
    dice_scores = []
    all_inputs = []
    all_masks = []
    all_preds = []
    all_img_names = []
    loop = tqdm(dataloader, leave=False, desc='Testing')
    with torch.no_grad():
        for inputs, masks, img_names in loop:
            inputs = inputs.to(device)
            masks = masks.to(device)

            outputs = model(inputs)

            preds = (outputs > 0.5).float()
            dice = dice_coefficient(preds, masks)
            dice_scores.append(dice.item())

            loop.set_postfix({'dice': dice.item()})

            all_inputs.extend(inputs.cpu())
            all_masks.extend(masks.cpu())
            all_preds.extend(preds.cpu())
            all_img_names.extend(img_names)

    # Save dice scores to Excel
    df_new = pd.DataFrame([dice_scores])
    excel_path = os.path.join(save_path, 'test_dice_scores.xlsx')
    df_new.to_excel(excel_path, index=False, header=False)

    return all_inputs, all_masks, all_preds, all_img_names

def save_losses_to_excel(train_losses, val_losses, save_path):
    epochs = list(range(1, len(train_losses) + 1))

    # Train losses
    df_train = pd.DataFrame([epochs, train_losses])
    df_train.to_excel(os.path.join(save_path, 'train_losses.xlsx'), index=False, header=False)

    # Validation losses
    df_val = pd.DataFrame([epochs, val_losses])
    df_val.to_excel(os.path.join(save_path, 'val_losses.xlsx'), index=False, header=False)

def plot_losses(train_losses, val_losses, save_path):
    epochs = list(range(1, len(train_losses) + 1))
    plt.figure()
    plt.plot(epochs, train_losses, 'b', label='Training loss')
    plt.plot(epochs, val_losses, 'r', label='Validation loss')
    plt.title('Training and Validation losses')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.savefig(os.path.join(save_path, 'losses.png'))
    plt.close()

def visualize_predictions(inputs, masks, preds, img_names, save_path):
    indices = random.sample(range(len(inputs)), 5)
    fig, axs = plt.subplots(5, 3, figsize=(12, 20))
    for i, idx in enumerate(indices):
        input_img = inputs[idx][0]  # Get the first channel
        mask_img = masks[idx][0]
        pred_img = preds[idx][0]
        img_name = img_names[idx]

        axs[i, 0].imshow(input_img, cmap='gray')
        axs[i, 0].set_title(f"Input Image: {img_name}")
        axs[i, 0].axis('off')

        axs[i, 1].imshow(mask_img, cmap='gray')
        axs[i, 1].set_title("Ground Truth")
        axs[i, 1].axis('off')

        axs[i, 2].imshow(pred_img, cmap='gray')
        axs[i, 2].set_title("Prediction")
        axs[i, 2].axis('off')
    plt.tight_layout()
    plt.savefig(os.path.join(save_path, 'test_predictions.png'))
    plt.close()
Explanation of Changes:
Validation Dice Scores:

Instead of attempting to append directly to an existing Excel file (which can cause issues due to sheet overwriting), the code now reads the existing Excel file into a DataFrame (df_existing), appends the new dice scores (df_new), and writes the combined DataFrame back to the Excel file.
This approach avoids the ValueError related to sheet existence.
Testing Dice Scores:

Since testing is typically done once, the dice scores are written directly to the Excel file without attempting to append.
Updated Instructions for Running the Code:
Ensure Dependencies:
Install required packages:
bash
Copy code
pip install torch torchvision numpy pandas matplotlib tqdm scikit-learn openpyxl torchsummary
Update Paths in main.py:
Replace '/path/to/dataset' with the path to your dataset containing the images and masks.
Replace '/path/to/save_directory' with the path where you want to save outputs like models, plots, and Excel files.
Run main.py:
Execute the script:
bash
Copy code
python main.py
Additional Notes:
Data Copying:

The main.py script copies the images and masks into separate directories for training, validation, and testing. Ensure you have sufficient disk space.
Data Loaders:

The sizes of the DataLoaders are printed to confirm correct data loading.
Model Summary and Parameters:

The model summary and total number of trainable parameters are printed for verification.
Progress Bars:

The tqdm progress bars now include descriptions ('Training', 'Validation', 'Testing') for clarity.
Excel File Handling:

The code avoids issues with Excel file writing by reading existing data and appending new data before writing back to the file.
Pandas Version:

Ensure you have a recent version of pandas installed (>=1.2.0) to support reading and writing Excel files with openpyxl.
Recap of Functionality:
Dataset Class (dataset.py):

Loads grayscale images and corresponding binary masks.
Applies necessary transformations to ensure correct input format.
UNet Model (model.py):

Defines a UNet architecture optimized for binary segmentation.
Training and Validation Functions (train.py):

Include functions for training, validation, testing, loss plotting, and prediction visualization.
Save losses and dice scores to Excel files.
Main Execution Script (main.py):

Splits the dataset into training, validation, and testing sets.
Sets up DataLoaders and model configurations.
Executes the training loop with proper progress updates.
Saves the trained model and outputs.
By making these adjustments, the script should now run without errors and meet all the specified requirements. If you encounter any further issues or need additional assistance, please let me know!