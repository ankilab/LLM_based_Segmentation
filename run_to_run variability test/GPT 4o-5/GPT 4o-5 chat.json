Skip to content
Chat history

You said:
ï¶ in separate scripts below, provide a complete ready-to-run Python implementation for a U-Net architecture using PyTorch, for binary segmentation of grayscale images. The dataset should consist of grayscale images and corresponding binary masks, which are located in 2 different folders, OR in the same path (the masks have the same name as the images, or with a suffix, like: "number.png" and the masks "number_seg.png", around 5000 samples in total. access and split directly using train_test_split on the index list and Subset, and do NOT duplicate or copy to new directory). It should work and provide correct predictions, and save the losses and dice scores as instructed below. write in separate scripts. The code should be structured into importable scripts with the following: 1. A custom Dataset class for loading the grayscale images and corresponding binary masks. (only the png files, ignore meta files or additional files in the directory) 2. A UNet model class definition using PyTorch, optimized for binary segmentation (with small foreground, mostly background) 3. Functions for the training procedure, validation procedure, and Testing procedure. Considerations for each part: 4. Ensure needed transforms on input image and mask pairs (Re-size images correctly, ensure gray scale and binaryâ€¦) 5. Avoid overfitting and data leakage (without using augmentations), choose appropriate hyperparameters, learning rate, batch size, etc â€¢ For Training and Validation: 6. Compute training and validation losses. 7. Track and save the average training loss for each epoch in a separate Excel file (train_losses.xlsx) in a given save path. The first row should contain the epoch numbers, and the second row should contain the corresponding average training loss for each epoch. 8. Similarly, save the validation loss for each epoch in an Excel file (val_losses.xlsx) with the same structure. 9. At the end of training, save both the entire model and the model's state dictionary (.pth files) in the save path 10. Calculate total training time from start to end, and print at the end of training 11. The progress, phase (train/validation), and all info should be shown epoch by epoch using tqdm progress bars during training, validation, and testing. 12. A function to visualize training losses and validation losses over epochs afterwards, on the same plot. Save plot in a specified save path as png. 13. During Validation: mean Dice scores should be calculated over each batch, for each epoch, and stored in an Excel file (epochs as rows and batches as columns). The Excel file (named â€œvalidation_dice_scoresâ€ should be saved at the specified save path after validation is done. 14. Do the same for the Testing and store dice the Dice scores the same way and save the excel file as â€œtest_dice_scoresâ€ after testing is done. â€¢ For Testing: 15. A function to visualize the predicted masks, the input image, and the ground truth, for 5 random samples, after testing is done. (subplots for 5 random samples in one plot, in 5 rows and 3 columns (title at top: Input Image, Ground Truth, Prediction). Also display image file name string above each image and mask. save the plot as .png). â€¢ For Main: 16. Shuffle the data, split the dataset into: 80% training, 10% validation, and 10% test sets using train_test_split. Print the sizes of each (how many images), and copy the splitted data (images and their respective masks) 17. DataLoader setup for training, validation, and testing sets. 18. Ensure correct data loading, print data loader sizes. 19. Also usig torchinfo, print model summary, and total number of model parameters (n learnable params) 20. All the above functionalities should be implemented in a modular way so that they can be imported as scripts or classes. 21. All visualizations should just be saved as png. No need to display the plots during running. 22. Ensure that everything can be executed in an if __name__ == "__main__": block with instructions for loading the dataset, configuring hyperparameters, and saving the trained model. The directory structure should only be: unet_segmentation/ â”œâ”€â”€ dataset.py â”œâ”€â”€ model.py â”œâ”€â”€ train.py â”œâ”€â”€ main.py
ChatGPT said:
Here's a fully modular and ready-to-run implementation of a U-Net architecture in PyTorch for binary segmentation of grayscale images, structured into the requested files under the directory:

unet_segmentation/
â”œâ”€â”€ dataset.py
â”œâ”€â”€ model.py
â”œâ”€â”€ train.py
â”œâ”€â”€ main.py
âœ… 1. dataset.py â€” Custom PyTorch Dataset
# unet_segmentation/dataset.py

import os
from PIL import Image
from torch.utils.data import Dataset
import torchvision.transforms as transforms

class SegmentationDataset(Dataset):
    def __init__(self, image_dir, mask_dir, file_list, mask_suffix="_seg", image_size=(256, 256)):
        self.image_dir = image_dir
        self.mask_dir = mask_dir
        self.file_list = file_list
        self.mask_suffix = mask_suffix
        self.image_size = image_size
        self.image_transform = transforms.Compose([
            transforms.Grayscale(num_output_channels=1),
            transforms.Resize(self.image_size),
            transforms.ToTensor(),
        ])
        self.mask_transform = transforms.Compose([
            transforms.Grayscale(num_output_channels=1),
            transforms.Resize(self.image_size),
            transforms.ToTensor(),
        ])

    def __len__(self):
        return len(self.file_list)

    def __getitem__(self, idx):
        img_name = self.file_list[idx]
        image_path = os.path.join(self.image_dir, img_name)
        mask_name = img_name.replace(".png", f"{self.mask_suffix}.png")
        mask_path = os.path.join(self.mask_dir, mask_name)

        image = Image.open(image_path).convert('L')
        mask = Image.open(mask_path).convert('L')

        image = self.image_transform(image)
        mask = self.mask_transform(mask)
        mask = (mask > 0.5).float()  # Ensure binary mask

        return image, mask, img_name
âœ… 2. model.py â€” U-Net Architecture
# unet_segmentation/model.py

import torch
import torch.nn as nn

class UNet(nn.Module):
    def __init__(self):
        super(UNet, self).__init__()

        def CBR(in_channels, out_channels):
            return nn.Sequential(
                nn.Conv2d(in_channels, out_channels, 3, padding=1),
                nn.BatchNorm2d(out_channels),
                nn.ReLU(inplace=True),
                nn.Conv2d(out_channels, out_channels, 3, padding=1),
                nn.BatchNorm2d(out_channels),
                nn.ReLU(inplace=True)
            )

        self.enc1 = CBR(1, 64)
        self.enc2 = CBR(64, 128)
        self.enc3 = CBR(128, 256)
        self.enc4 = CBR(256, 512)

        self.pool = nn.MaxPool2d(2)

        self.bottleneck = CBR(512, 1024)

        self.upconv4 = nn.ConvTranspose2d(1024, 512, 2, stride=2)
        self.dec4 = CBR(1024, 512)
        self.upconv3 = nn.ConvTranspose2d(512, 256, 2, stride=2)
        self.dec3 = CBR(512, 256)
        self.upconv2 = nn.ConvTranspose2d(256, 128, 2, stride=2)
        self.dec2 = CBR(256, 128)
        self.upconv1 = nn.ConvTranspose2d(128, 64, 2, stride=2)
        self.dec1 = CBR(128, 64)

        self.conv_final = nn.Conv2d(64, 1, 1)

    def forward(self, x):
        e1 = self.enc1(x)
        e2 = self.enc2(self.pool(e1))
        e3 = self.enc3(self.pool(e2))
        e4 = self.enc4(self.pool(e3))

        b = self.bottleneck(self.pool(e4))

        d4 = self.dec4(torch.cat([self.upconv4(b), e4], dim=1))
        d3 = self.dec3(torch.cat([self.upconv3(d4), e3], dim=1))
        d2 = self.dec2(torch.cat([self.upconv2(d3), e2], dim=1))
        d1 = self.dec1(torch.cat([self.upconv1(d2), e1], dim=1))

        return torch.sigmoid(self.conv_final(d1))
âœ… 3. train.py â€” Training, Validation, Testing Logic
# unet_segmentation/train.py

import time
import torch
import torch.nn as nn
import torch.optim as optim
import pandas as pd
import matplotlib.pyplot as plt
import random
import numpy as np
from tqdm import tqdm
from torch.utils.data import DataLoader
import os

def dice_score(preds, targets, threshold=0.5):
    preds = (preds > threshold).float()
    intersection = (preds * targets).sum(dim=(1, 2, 3))
    union = preds.sum(dim=(1, 2, 3)) + targets.sum(dim=(1, 2, 3))
    dice = (2 * intersection + 1e-7) / (union + 1e-7)
    return dice

def save_losses(train_losses, val_losses, save_path):
    train_df = pd.DataFrame([train_losses], index=["Train"], columns=[f"Epoch {i+1}" for i in range(len(train_losses))])
    val_df = pd.DataFrame([val_losses], index=["Val"], columns=[f"Epoch {i+1}" for i in range(len(val_losses))])
    train_df.to_excel(os.path.join(save_path, "train_losses.xlsx"))
    val_df.to_excel(os.path.join(save_path, "val_losses.xlsx"))

def plot_losses(train_losses, val_losses, save_path):
    plt.figure()
    plt.plot(train_losses, label='Train Loss')
    plt.plot(val_losses, label='Val Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.title('Training and Validation Loss')
    plt.savefig(os.path.join(save_path, 'loss_plot.png'))
    plt.close()

def save_dice_scores(dice_matrix, save_path, file_name):
    df = pd.DataFrame(dice_matrix)
    df.to_excel(os.path.join(save_path, f"{file_name}.xlsx"), index=False)

def train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs, save_path):
    train_losses, val_losses = [], []
    validation_dice_scores = []

    start_time = time.time()

    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        loop = tqdm(train_loader, desc=f"Epoch [{epoch+1}/{num_epochs}] - Train", leave=False)
        for images, masks, _ in loop:
            images, masks = images.to(device), masks.to(device)
            outputs = model(images)
            loss = criterion(outputs, masks)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            running_loss += loss.item() * images.size(0)

        avg_train_loss = running_loss / len(train_loader.dataset)
        train_losses.append(avg_train_loss)

        model.eval()
        val_loss = 0.0
        val_dice_scores = []
        with torch.no_grad():
            loop = tqdm(val_loader, desc=f"Epoch [{epoch+1}/{num_epochs}] - Val", leave=False)
            for images, masks, _ in loop:
                images, masks = images.to(device), masks.to(device)
                outputs = model(images)
                loss = criterion(outputs, masks)
                val_loss += loss.item() * images.size(0)
                val_dice = dice_score(outputs, masks)
                val_dice_scores.append(val_dice.cpu().numpy())

        avg_val_loss = val_loss / len(val_loader.dataset)
        val_losses.append(avg_val_loss)
        validation_dice_scores.append(np.mean(val_dice_scores, axis=0))

    duration = time.time() - start_time
    print(f"Training completed in {duration:.2f} seconds.")

    torch.save(model, os.path.join(save_path, "unet_full_model.pth"))
    torch.save(model.state_dict(), os.path.join(save_path, "unet_state_dict.pth"))

    save_losses(train_losses, val_losses, save_path)
    plot_losses(train_losses, val_losses, save_path)
    save_dice_scores(validation_dice_scores, save_path, "validation_dice_scores")

def test_model(model, test_loader, device, save_path):
    model.eval()
    test_dice_scores = []
    predictions = []

    with torch.no_grad():
        loop = tqdm(test_loader, desc="Testing", leave=False)
        for images, masks, names in loop:
            images, masks = images.to(device), masks.to(device)
            outputs = model(images)
            dice = dice_score(outputs, masks)
            test_dice_scores.append(dice.cpu().numpy())
            predictions.append((images.cpu(), masks.cpu(), outputs.cpu(), names))

    save_dice_scores(test_dice_scores, save_path, "test_dice_scores")
    visualize_predictions(predictions, save_path)

def visualize_predictions(predictions, save_path):
    samples = random.sample(predictions, 5)
    fig, axes = plt.subplots(5, 3, figsize=(12, 18))
    for i, (img, mask, pred, name) in enumerate(samples):
        axes[i, 0].imshow(img[0][0], cmap='gray')
        axes[i, 0].set_title(f"Input\n{name[0]}")
        axes[i, 1].imshow(mask[0][0], cmap='gray')
        axes[i, 1].set_title("Ground Truth")
        axes[i, 2].imshow(pred[0][0] > 0.5, cmap='gray')
        axes[i, 2].set_title("Prediction")
        for j in range(3):
            axes[i, j].axis('off')
    plt.tight_layout()
    plt.savefig(os.path.join(save_path, "predictions.png"))
    plt.close()
âœ… 4. main.py â€” Dataset Split, Model Setup, Training Execution
# unet_segmentation/main.py

import os
import torch
import random
import numpy as np
from sklearn.model_selection import train_test_split
from torch.utils.data import Subset, DataLoader
from torchinfo import summary

from dataset import SegmentationDataset
from model import UNet
from train import train_model, test_model

if __name__ == "__main__":
    # Paths
    image_dir = "data/images"
    mask_dir = "data/masks"
    save_path = "results"
    os.makedirs(save_path, exist_ok=True)

    # Hyperparameters
    image_size = (256, 256)
    batch_size = 8
    learning_rate = 1e-4
    num_epochs = 20

    # Prepare file list
    all_files = [f for f in os.listdir(image_dir) if f.endswith(".png")]
    all_files.sort()
    random.shuffle(all_files)

    # Split dataset
    train_idx, test_idx = train_test_split(range(len(all_files)), test_size=0.2, random_state=42)
    val_idx, test_idx = train_test_split(test_idx, test_size=0.5, random_state=42)

    print(f"Train size: {len(train_idx)}, Val size: {len(val_idx)}, Test size: {len(test_idx)}")

    dataset = SegmentationDataset(image_dir, mask_dir, all_files, image_size=image_size)
    train_set = Subset(dataset, train_idx)
    val_set = Subset(dataset, val_idx)
    test_set = Subset(dataset, test_idx)

    # DataLoaders
    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)
    test_loader = DataLoader(test_set, batch_size=1, shuffle=False)

    print(f"Train batches: {len(train_loader)}, Val batches: {len(val_loader)}, Test batches: {len(test_loader)}")

    # Device
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # Model
    model = UNet().to(device)
    summary(model, input_size=(1, 1, *image_size))
    print(f"Total trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}")

    # Loss and Optimizer
    criterion = torch.nn.BCELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

    # Training
    train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs, save_path)

    # Testing
    test_model(model, test_loader, device, save_path)
If you'd like, I can zip this directory and provide it to you for download or adjust any part (like file names, directory structures, optimizer type, etc.). Let me know!

You said:
C:\Users\qy44lyfe\.conda\envs\Swallowenv\python.exe "D:/qy44lyfe/LLM segmentation/github repo/LLM_based_Segmentation/run_to_run variability test/GPT 4o-5/main.py"
Train size: 799, Val size: 100, Test size: 100
Train batches: 100, Val batches: 13, Test batches: 100
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
UNet                                     [1, 1, 256, 256]          --
â”œâ”€Sequential: 1-1                        [1, 64, 256, 256]         --
â”‚    â””â”€Conv2d: 2-1                       [1, 64, 256, 256]         640
â”‚    â””â”€BatchNorm2d: 2-2                  [1, 64, 256, 256]         128
â”‚    â””â”€ReLU: 2-3                         [1, 64, 256, 256]         --
â”‚    â””â”€Conv2d: 2-4                       [1, 64, 256, 256]         36,928
â”‚    â””â”€BatchNorm2d: 2-5                  [1, 64, 256, 256]         128
â”‚    â””â”€ReLU: 2-6                         [1, 64, 256, 256]         --
â”œâ”€MaxPool2d: 1-2                         [1, 64, 128, 128]         --
â”œâ”€Sequential: 1-3                        [1, 128, 128, 128]        --
â”‚    â””â”€Conv2d: 2-7                       [1, 128, 128, 128]        73,856
â”‚    â””â”€BatchNorm2d: 2-8                  [1, 128, 128, 128]        256
â”‚    â””â”€ReLU: 2-9                         [1, 128, 128, 128]        --
â”‚    â””â”€Conv2d: 2-10                      [1, 128, 128, 128]        147,584
â”‚    â””â”€BatchNorm2d: 2-11                 [1, 128, 128, 128]        256
â”‚    â””â”€ReLU: 2-12                        [1, 128, 128, 128]        --
â”œâ”€MaxPool2d: 1-4                         [1, 128, 64, 64]          --
â”œâ”€Sequential: 1-5                        [1, 256, 64, 64]          --
â”‚    â””â”€Conv2d: 2-13                      [1, 256, 64, 64]          295,168
â”‚    â””â”€BatchNorm2d: 2-14                 [1, 256, 64, 64]          512
â”‚    â””â”€ReLU: 2-15                        [1, 256, 64, 64]          --
â”‚    â””â”€Conv2d: 2-16                      [1, 256, 64, 64]          590,080
â”‚    â””â”€BatchNorm2d: 2-17                 [1, 256, 64, 64]          512
â”‚    â””â”€ReLU: 2-18                        [1, 256, 64, 64]          --
â”œâ”€MaxPool2d: 1-6                         [1, 256, 32, 32]          --
â”œâ”€Sequential: 1-7                        [1, 512, 32, 32]          --
â”‚    â””â”€Conv2d: 2-19                      [1, 512, 32, 32]          1,180,160
â”‚    â””â”€BatchNorm2d: 2-20                 [1, 512, 32, 32]          1,024
â”‚    â””â”€ReLU: 2-21                        [1, 512, 32, 32]          --
â”‚    â””â”€Conv2d: 2-22                      [1, 512, 32, 32]          2,359,808
â”‚    â””â”€BatchNorm2d: 2-23                 [1, 512, 32, 32]          1,024
â”‚    â””â”€ReLU: 2-24                        [1, 512, 32, 32]          --
â”œâ”€MaxPool2d: 1-8                         [1, 512, 16, 16]          --
â”œâ”€Sequential: 1-9                        [1, 1024, 16, 16]         --
â”‚    â””â”€Conv2d: 2-25                      [1, 1024, 16, 16]         4,719,616
â”‚    â””â”€BatchNorm2d: 2-26                 [1, 1024, 16, 16]         2,048
â”‚    â””â”€ReLU: 2-27                        [1, 1024, 16, 16]         --
â”‚    â””â”€Conv2d: 2-28                      [1, 1024, 16, 16]         9,438,208
â”‚    â””â”€BatchNorm2d: 2-29                 [1, 1024, 16, 16]         2,048
â”‚    â””â”€ReLU: 2-30                        [1, 1024, 16, 16]         --
â”œâ”€ConvTranspose2d: 1-10                  [1, 512, 32, 32]          2,097,664
â”œâ”€Sequential: 1-11                       [1, 512, 32, 32]          --
â”‚    â””â”€Conv2d: 2-31                      [1, 512, 32, 32]          4,719,104
â”‚    â””â”€BatchNorm2d: 2-32                 [1, 512, 32, 32]          1,024
â”‚    â””â”€ReLU: 2-33                        [1, 512, 32, 32]          --
â”‚    â””â”€Conv2d: 2-34                      [1, 512, 32, 32]          2,359,808
â”‚    â””â”€BatchNorm2d: 2-35                 [1, 512, 32, 32]          1,024
â”‚    â””â”€ReLU: 2-36                        [1, 512, 32, 32]          --
â”œâ”€ConvTranspose2d: 1-12                  [1, 256, 64, 64]          524,544
â”œâ”€Sequential: 1-13                       [1, 256, 64, 64]          --
â”‚    â””â”€Conv2d: 2-37                      [1, 256, 64, 64]          1,179,904
â”‚    â””â”€BatchNorm2d: 2-38                 [1, 256, 64, 64]          512
â”‚    â””â”€ReLU: 2-39                        [1, 256, 64, 64]          --
â”‚    â””â”€Conv2d: 2-40                      [1, 256, 64, 64]          590,080
â”‚    â””â”€BatchNorm2d: 2-41                 [1, 256, 64, 64]          512
â”‚    â””â”€ReLU: 2-42                        [1, 256, 64, 64]          --
â”œâ”€ConvTranspose2d: 1-14                  [1, 128, 128, 128]        131,200
â”œâ”€Sequential: 1-15                       [1, 128, 128, 128]        --
â”‚    â””â”€Conv2d: 2-43                      [1, 128, 128, 128]        295,040
â”‚    â””â”€BatchNorm2d: 2-44                 [1, 128, 128, 128]        256
â”‚    â””â”€ReLU: 2-45                        [1, 128, 128, 128]        --
â”‚    â””â”€Conv2d: 2-46                      [1, 128, 128, 128]        147,584
â”‚    â””â”€BatchNorm2d: 2-47                 [1, 128, 128, 128]        256
â”‚    â””â”€ReLU: 2-48                        [1, 128, 128, 128]        --
â”œâ”€ConvTranspose2d: 1-16                  [1, 64, 256, 256]         32,832
â”œâ”€Sequential: 1-17                       [1, 64, 256, 256]         --
â”‚    â””â”€Conv2d: 2-49                      [1, 64, 256, 256]         73,792
â”‚    â””â”€BatchNorm2d: 2-50                 [1, 64, 256, 256]         128
â”‚    â””â”€ReLU: 2-51                        [1, 64, 256, 256]         --
â”‚    â””â”€Conv2d: 2-52                      [1, 64, 256, 256]         36,928
â”‚    â””â”€BatchNorm2d: 2-53                 [1, 64, 256, 256]         128
â”‚    â””â”€ReLU: 2-54                        [1, 64, 256, 256]         --
â”œâ”€Conv2d: 1-18                           [1, 1, 256, 256]          65
==========================================================================================
Total params: 31,042,369
Trainable params: 31,042,369
Non-trainable params: 0
Total mult-adds (G): 54.57
==========================================================================================
Input size (MB): 0.26
Forward/backward pass size (MB): 575.14
Params size (MB): 124.17
Estimated Total Size (MB): 699.58
==========================================================================================
Epoch [1/2] - Train:   0%|          | 0/100 [00:00<?, ?it/s]Total trainable parameters: 31042369
Traceback (most recent call last):
  File "D:\qy44lyfe\LLM segmentation\github repo\LLM_based_Segmentation\run_to_run variability test\GPT 4o-5\main.py", line 64, in <module>
    train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs, save_path)
  File "D:\qy44lyfe\LLM segmentation\github repo\LLM_based_Segmentation\run_to_run variability test\GPT 4o-5\train.py", line 80, in train_model
    validation_dice_scores.append(np.mean(val_dice_scores, axis=0))
  File "C:\Users\qy44lyfe\.conda\envs\Swallowenv\lib\site-packages\numpy\core\fromnumeric.py", line 3504, in mean
    return _methods._mean(a, axis=axis, dtype=dtype,
  File "C:\Users\qy44lyfe\.conda\envs\Swallowenv\lib\site-packages\numpy\core\_methods.py", line 102, in _mean
    arr = asanyarray(a)
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (13,) + inhomogeneous part.

Process finished with exit code 1
ChatGPT said:
Thanks for the detailed traceback and logs â€” that was helpful.

âœ… The issue
The error you're getting:

ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (13,) + inhomogeneous part.
means that val_dice_scores is a list of NumPy arrays of different lengths (or shapes), which cannot be stacked or averaged using np.mean(..., axis=0).

ğŸ“ Why itâ€™s happening
In your train_model() function (inside train.py), during validation, you're doing:

val_dice_scores.append(val_dice.cpu().numpy())
...
validation_dice_scores.append(np.mean(val_dice_scores, axis=0))
But val_dice.cpu().numpy() is a batch of dice scores, i.e., itâ€™s shape is something like (batch_size,), and since your validation set may have 13 batches of different sizes, the result is a list of arrays of different lengths.

âœ… Fix: Aggregate correctly per batch
If you want to store one dice score per batch (i.e., mean over the batch), just do:

ğŸ”§ Replace this:
val_dice_scores.append(val_dice.cpu().numpy())
âœ… With this:
val_dice_scores.append(val_dice.mean().item())
Then this line will work as expected:

validation_dice_scores.append(val_dice_scores)
This way, validation_dice_scores becomes a list of lists (one per epoch), where each sublist contains a single scalar per batch â€” ideal for saving into Excel later.

ğŸ’¡ Summary of edits to train.py
In the train_model() function inside train.py, modify the validation loop as follows:

ğŸ” Replace:
val_dice_scores.append(val_dice.cpu().numpy())
...
validation_dice_scores.append(np.mean(val_dice_scores, axis=0))
âœ… With:
val_dice_scores.append(val_dice.mean().item())  # one score per batch
...
validation_dice_scores.append(val_dice_scores)  # list of batch means for this epoch
This will avoid the inhomogeneous shape issue and allow your dice matrix to save cleanly into an Excel file.

Would you like me to update and repost the corrected version of train.py?




No file chosenNo file chosen
ChatGPT can make mistakes. Check important info. See Cookie Preferences.
