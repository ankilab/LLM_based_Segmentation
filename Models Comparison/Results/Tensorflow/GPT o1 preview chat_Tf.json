Please provide a complete ready-to-run Python implementation for a U-Net architecture using Tensorflow, for binary segmentation of grayscale images. The dataset should consist of grayscale images and corresponding binary masks, which are located in the same path (the images are named with numbering like "number.png" and the masks "number_seg.png", around 5000 samples in total). It should work and provide correct predictions, and save the losses and dice scores as instructed below. The code should be structured into importable scripts with the following: 

23.	A custom Dataset class for loading the grayscale images and corresponding binary masks. (only the png files, ignore meta files or additional files in the directory)
24.	A UNet model class definition using Tensorflow, optimized for binary segmentation (with small foreground, mostly background)
25.	Functions for the training procedure, validation procedure, and Testing procedure.

Considerations for each part:
26.	Ensure needed transforms on input image and mask pairs (Re-size images correctly, ensure gray scale and binary…)
27.	Avoid overfitting and data leakage (without using augmentations), choose appropriate hyperparameters, learning rate, batch size, etc

•	For Training and Validation:

28.	Compute training and validation losses.
29.	Track and save the average training loss for each epoch in a separate Excel file (train_losses.xlsx) in a given save path. The first row should contain the epoch numbers, and the second row should contain the corresponding average training loss for each epoch.
30.	Similarly, save the validation loss for each epoch in an Excel file (val_losses.xlsx) with the same structure.
31.	At the end of training, save both the entire model and the model's state dictionary (.pth files) in the save path
32.	Calculate total training time from start to end, and print at the end of training
33.	The progress, phase (train/validation), and all info should be shown epoch by epoch using tqdm progress bars during training, validation, and testing.
34.	A function to visualize training losses and validation losses over epochs afterwards, on the same plot. Save plot in a specified save path as png. 
35.	During Validation: Dice scores should be calculated for each batch, and all dice coefficients for the entire epoch should be stored in an Excel file, where each row in the Excel file should represent an epoch, and each column should represent a batch. The Excel file (named “validation_dice_scores” should be saved at the specified save path after validation is done.
36.	Do the same for the Testing and store dice the Dice scores the same way and save the excel file as “test_dice_scores” after testing is done.

•	For Testing:

37.	A function to visualize the predicted masks, the input image, and the ground truth, for 5 random samples, after testing is done. (subplots for 5 random samples in one plot, in 5 rows and 3 columns (title at top: Input Image, Ground Truth, Prediction). Also display image file name /id string above each image and mask. save the plot as .png).

•	For Main:

38.	Shuffle the data, split the dataset into: 80% training, 10% validation, and 10% test sets using train_test_split. Print the sizes of each (how many images), and copy the splitted data (images and their respective masks) 
39.	DataLoader setup for training, validation, and testing sets.
40.	Ensure correct data loading, print data loader sizes.
41.	Also print model summary, and total number of model parameters (n learnable params)

42.	All the above functionalities should be implemented in a modular way so that they can be imported as scripts or classes.
43.	All visualizations should just be saved as png. No need to display the plots during running.
44.	Ensure that everything can be executed in an if __name__ == "__main__": block with instructions for loading the dataset, configuring hyperparameters, and saving the trained model.
The directory structure should only be:
unet_segmentation/
├── dataset.py
├── model.py
├── train.py
├── main.py
ChatGPT

Thought for 1m 35s

Crafting U-Net for segmentation

I'm pulling together a TensorFlow code for a U-Net model, optimized for binary segmentation. It includes a dedicated class for loading datasets, ensuring precise image and mask handling, and optimizing models with hyperparameters like learning rate and batch size.

Tracking progress

I’m breaking down the steps to compute training and validation losses, then saving the average training loss for each epoch in an Excel file.

Tracking progress

OK, let me see. The plan is to maintain detailed epoch records of training and validation losses in an Excel file. It’ll include tracking progress with tqdm and saving the model with its state dictionary. Dusting off data visualization for a clear picture.

Organizing the task involves saving dice scores post-validation and testing, followed by visualizing predictions versus actual data for random samples, then shuffling and splitting the dataset for training, validation, and testing.

Ensuring efficient data handling

I’m sourcing image and mask data, structuring data loaders for training, validation, and testing. Then, I’m meticulously printing sizes of each data loader.

Setting up the structure

I’m setting up Python code with TensorFlow, using Keras API. The dataset.py will handle grayscale images and masks. model.py will define a U-Net model for binary segmentation. train.py will manage training, validation, and testing. main.py will oversee data handling, model setup, and training loop.

Crafting the Dataset Class

I'm setting up a SegmentationDataset class to handle grayscale images and binary masks using the tf.data API in TensorFlow. This class will streamline data loading and manage generators for training, validation, and testing.

Piecing together the plan

Starting with dataset.py, crafting SegmentationDataset to handle images, masks, and split data for training, validation, and testing. Next, diving into model.py, I’m setting up a U-Net model for binary segmentation.

Outlining steps

I’m developing the training procedure, starting with defining functions for training, validation, and testing in train.py. Next, I’ll move to data handling in main.py, including dataset loading, splitting, data loader setup, and the training loop.

Utilizing tf.data API

OK, let me see. Since TensorFlow is the go-to, I'm pulling data in with the tf.data API, ensuring a smooth load.

Mapping the process

I’m starting with SegmentationDataset to load image and mask paths, split the dataset, and create TensorFlow data generators.

Crafting the U-Net model

I'm piecing together the architecture for the U-Net model, ensuring it centers on skip connections to maintain data fidelity throughout processing.

Constructing the model

I’m building a U-Net for binary segmentation, focusing on small foregrounds. The architecture includes a multi-level encoding path, a bottleneck, and a multi-level decoding path with various convolutional layers and skip connections.

Integrating loss functions

I’m thinking about incorporating binary crossentropy or Dice loss to address class imbalance. Also, defining a custom loss function with both is feasible. Saving and tracking model parameters and summaries is crucial.

Piecing together options

I'm working through saving model weights and using pandas and tqdm for progress and timing. Now, I’m focusing on drafting functions for training, validation, and testing in train.py.

Enhancing model evaluation

I implemented Dice coefficient and combined loss functions to evaluate model performance, and designed functions for training, validation, testing, and visualization to track progress and results effectively.

Enhancing data handling

I'm considering modifying the SegmentationDataset class to include file names in the dataset. This involves tweaking the preprocess_image method to output file names and possibly redefining the data loading function.

Refining dataset preparation

I’m working on enhancing the get_tf_data_generator method to include filenames in the outputs. This adjustment might challenge Keras expectations, as it typically anticipates only images and masks.

Enhancing the testing function

I'm pulling together ideas to refine the testing function by incorporating image paths and mask paths as outputs. This adjustment leverages separate lists, simplifying task management within the test_model function.

Weighing options for testing

I'm thinking through standard Python loops versus TensorFlow for image processing. Also considering a TensorFlow dataset for compiling images, masks, and names.

Loading data

I’m bringing together datasets, setting up data loaders, and ensuring proper loading sequences for training, validation, and testing datasets.

Building the model

Constructing a U-Net model, compiling it with the Adam optimizer, binary crossentropy loss, and accuracy metric, and then examining its parameters.

Training the model

I’m orchestrating the training process, plotting losses, and testing the model on defined datasets.

Organizing datasets

I’m starting to map out a strategy to copy images and masks into train, val, and test directories by reviewing main.py after dataset splitting.

Organizing directories

I’m setting up directories for train, validation, and test datasets, ensuring images and masks are separated into 'images' and 'masks' folders within each directory.

Copying files

Now I’m copying images and masks to their respective directories, leveraging shutil to ensure organized data segmentation.

Calculating and storing

I’m gathering Dice coefficients for each batch during testing, then storing these scores in an Excel file, ensuring each row represents an epoch and each column signifies a batch.

Immersing in visualizing samples

I'm working through visualizing five random samples by selecting indices or collecting batches. This involves displaying predicted masks, input images, and ground truth, along with image file names or IDs, after testing.

Gathering test results

I’m noting that test_model is tasked with evaluating the model. It aggregates dice scores for each batch, stashes example images and their masks, and compiles predictions for visualization.

Enhancing visualization functions

I adjusted the visualize_predictions function to improve accuracy. Now, it clearly shows input images, ground truth masks, and prediction results from the model's output.

Managing training dynamics

I’m ensuring no overfitting or data leakage in train_model. Adjusting hyperparameters like learning rate and batch size effectively manages these aspects.

python
Copy code
# dataset.py

import os
import tensorflow as tf
import numpy as np
from sklearn.model_selection import train_test_split

class SegmentationDataset:
    def __init__(self, data_path, img_height=256, img_width=256):
        self.data_path = data_path
        self.img_height = img_height
        self.img_width = img_width

        self.image_paths = []
        self.mask_paths = []
        self.load_image_mask_paths()

    def load_image_mask_paths(self):
        image_files = [f for f in os.listdir(self.data_path) if f.endswith('.png') and not f.endswith('_seg.png')]
        for img_file in image_files:
            img_path = os.path.join(self.data_path, img_file)
            mask_file = img_file.replace('.png', '_seg.png')
            mask_path = os.path.join(self.data_path, mask_file)
            if os.path.exists(mask_path):
                self.image_paths.append(img_path)
                self.mask_paths.append(mask_path)

    def get_dataset(self):
        return self.image_paths, self.mask_paths

    def split_dataset(self, test_size=0.2, val_size=0.1, random_state=42):
        img_train_val, img_test, mask_train_val, mask_test = train_test_split(
            self.image_paths, self.mask_paths, test_size=test_size, random_state=random_state)

        val_size_adj = val_size / (1 - test_size)
        img_train, img_val, mask_train, mask_val = train_test_split(
            img_train_val, mask_train_val, test_size=val_size_adj, random_state=random_state)

        return (img_train, mask_train), (img_val, mask_val), (img_test, mask_test)

    def preprocess_image(self, image_path, mask_path):
        image = tf.io.read_file(image_path)
        image = tf.image.decode_png(image, channels=1)
        image = tf.image.resize(image, [self.img_height, self.img_width])
        image = tf.cast(image, tf.float32) / 255.0

        mask = tf.io.read_file(mask_path)
        mask = tf.image.decode_png(mask, channels=1)
        mask = tf.image.resize(mask, [self.img_height, self.img_width])
        mask = tf.cast(mask, tf.float32) / 255.0
        mask = tf.round(mask)

        return image, mask

    def get_tf_data_generator(self, image_paths, mask_paths, batch_size=16, shuffle=True):
        dataset = tf.data.Dataset.from_tensor_slices((image_paths, mask_paths))
        if shuffle:
            dataset = dataset.shuffle(buffer_size=len(image_paths))
        dataset = dataset.map(lambda x, y: self.preprocess_image(x, y), num_parallel_calls=tf.data.AUTOTUNE)
        dataset = dataset.batch(batch_size)
        dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)
        return dataset
python
Copy code
# model.py

import tensorflow as tf
from tensorflow.keras import layers, models

def unet_model(input_size=(256, 256, 1)):
    inputs = layers.Input(input_size)

    # Encoding path
    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)
    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv1)
    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)

    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(pool1)
    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv2)
    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)

    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(pool2)
    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(conv3)
    pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)

    conv4 = layers.Conv2D(512, 3, activation='relu', padding='same')(pool3)
    conv4 = layers.Conv2D(512, 3, activation='relu', padding='same')(conv4)
    drop4 = layers.Dropout(0.5)(conv4)
    pool4 = layers.MaxPooling2D(pool_size=(2, 2))(drop4)

    # Bottleneck
    conv5 = layers.Conv2D(1024, 3, activation='relu', padding='same')(pool4)
    conv5 = layers.Conv2D(1024, 3, activation='relu', padding='same')(conv5)
    drop5 = layers.Dropout(0.5)(conv5)

    # Decoding path
    up6 = layers.Conv2D(512, 2, activation='relu', padding='same')(layers.UpSampling2D(size=(2, 2))(drop5))
    merge6 = layers.concatenate([drop4, up6], axis=3)
    conv6 = layers.Conv2D(512, 3, activation='relu', padding='same')(merge6)
    conv6 = layers.Conv2D(512, 3, activation='relu', padding='same')(conv6)

    up7 = layers.Conv2D(256, 2, activation='relu', padding='same')(layers.UpSampling2D(size=(2, 2))(conv6))
    merge7 = layers.concatenate([conv3, up7], axis=3)
    conv7 = layers.Conv2D(256, 3, activation='relu', padding='same')(merge7)
    conv7 = layers.Conv2D(256, 3, activation='relu', padding='same')(conv7)

    up8 = layers.Conv2D(128, 2, activation='relu', padding='same')(layers.UpSampling2D(size=(2, 2))(conv7))
    merge8 = layers.concatenate([conv2, up8], axis=3)
    conv8 = layers.Conv2D(128, 3, activation='relu', padding='same')(merge8)
    conv8 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv8)

    up9 = layers.Conv2D(64, 2, activation='relu', padding='same')(layers.UpSampling2D(size=(2, 2))(conv8))
    merge9 = layers.concatenate([conv1, up9], axis=3)
    conv9 = layers.Conv2D(64, 3, activation='relu', padding='same')(merge9)
    conv9 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv9)
    conv9 = layers.Conv2D(2, 3, activation='relu', padding='same')(conv9)

    outputs = layers.Conv2D(1, 1, activation='sigmoid')(conv9)

    model = models.Model(inputs=inputs, outputs=outputs)
    return model
python
Copy code
# train.py

import tensorflow as tf
import numpy as np
import time
from tqdm import tqdm
import pandas as pd
import matplotlib.pyplot as plt
import os

def dice_coefficient(y_true, y_pred, smooth=1):
    y_true_f = tf.reshape(y_true, [-1])
    y_pred_f = tf.reshape(y_pred, [-1])
    intersection = tf.reduce_sum(y_true_f * y_pred_f)
    dice = (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)
    return dice

def dice_loss(y_true, y_pred):
    return 1 - dice_coefficient(y_true, y_pred)

def combined_loss(y_true, y_pred):
    bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)
    dl = dice_loss(y_true, y_pred)
    return bce + dl

def train_model(model, train_dataset, val_dataset, epochs, save_path):
    optimizer = tf.keras.optimizers.Adam()
    train_loss_metric = tf.keras.metrics.Mean()
    val_loss_metric = tf.keras.metrics.Mean()

    train_losses = []
    val_losses = []

    validation_dice_scores = []

    total_start = time.time()
    for epoch in range(epochs):
        print(f'Epoch {epoch+1}/{epochs}')
        train_loss_metric.reset_states()
        train_dataset_tqdm = tqdm(train_dataset, desc='Training', position=0, leave=True)
        for step, (images, masks) in enumerate(train_dataset_tqdm):
            with tf.GradientTape() as tape:
                predictions = model(images, training=True)
                loss = combined_loss(masks, predictions)
            gradients = tape.gradient(loss, model.trainable_variables)
            optimizer.apply_gradients(zip(gradients, model.trainable_variables))
            train_loss_metric.update_state(loss)
            train_dataset_tqdm.set_postfix({'loss': train_loss_metric.result().numpy()})

        train_losses.append(train_loss_metric.result().numpy())

        val_loss_metric.reset_states()
        dice_scores = []
        val_dataset_tqdm = tqdm(val_dataset, desc='Validation', position=0, leave=True)
        for step, (images, masks) in enumerate(val_dataset_tqdm):
            predictions = model(images, training=False)
            loss = combined_loss(masks, predictions)
            val_loss_metric.update_state(loss)
            dice = dice_coefficient(masks, predictions).numpy()
            dice_scores.append(dice)
            val_dataset_tqdm.set_postfix({'loss': val_loss_metric.result().numpy(), 'dice': dice})

        val_losses.append(val_loss_metric.result().numpy())
        validation_dice_scores.append(dice_scores)

    total_end = time.time()
    total_time = total_end - total_start
    print(f"Total training time: {total_time} seconds")

    os.makedirs(save_path, exist_ok=True)
    model.save(os.path.join(save_path, 'unet_model.h5'))
    model.save_weights(os.path.join(save_path, 'unet_weights.h5'))

    epochs_list = list(range(1, epochs +1))
    train_loss_df = pd.DataFrame({'Epoch': epochs_list, 'Train Loss': train_losses})
    val_loss_df = pd.DataFrame({'Epoch': epochs_list, 'Val Loss': val_losses})

    train_loss_df.to_excel(os.path.join(save_path, 'train_losses.xlsx'), index=False)
    val_loss_df.to_excel(os.path.join(save_path, 'val_losses.xlsx'), index=False)

    val_dice_df = pd.DataFrame(validation_dice_scores)
    val_dice_df.to_excel(os.path.join(save_path, 'validation_dice_scores.xlsx'), index=False)

    return train_losses, val_losses

def test_model(model, test_dataset, save_path, test_image_paths):
    test_dice_scores = []
    test_dataset_tqdm = tqdm(test_dataset, desc='Testing', position=0, leave=True)
    dice_scores_epoch = []
    images_list = []
    masks_list = []
    preds_list = []
    file_names_list = []
    for step, (images, masks) in enumerate(test_dataset_tqdm):
        predictions = model(images, training=False)
        dice = dice_coefficient(masks, predictions).numpy()
        dice_scores_epoch.append(dice)
        if len(images_list) < 5 * images.shape[0]:
            images_list.extend(images.numpy())
            masks_list.extend(masks.numpy())
            preds_list.extend(predictions.numpy())
            start_idx = step * images.shape[0]
            end_idx = start_idx + images.shape[0]
            file_names_list.extend(test_image_paths[start_idx:end_idx])

    test_dice_df = pd.DataFrame([dice_scores_epoch])
    test_dice_df.to_excel(os.path.join(save_path, 'test_dice_scores.xlsx'), index=False)

    visualize_predictions(images_list, masks_list, preds_list, file_names_list, save_path)

def visualize_predictions(images, masks, predictions, file_names, save_path):
    num_samples = min(5, len(images))
    indices = np.random.choice(len(images), num_samples, replace=False)
    fig, axs = plt.subplots(num_samples, 3, figsize=(15, 5*num_samples))
    for i, idx in enumerate(indices):
        axs[i, 0].imshow(images[idx].squeeze(), cmap='gray')
        axs[i, 0].set_title('Input Image\n'+os.path.basename(file_names[idx]))
        axs[i, 1].imshow(masks[idx].squeeze(), cmap='gray')
        axs[i, 1].set_title('Ground Truth\n'+os.path.basename(file_names[idx]))
        axs[i, 2].imshow(predictions[idx].squeeze() > 0.5, cmap='gray')
        axs[i, 2].set_title('Prediction\n'+os.path.basename(file_names[idx]))
    plt.tight_layout()
    plt.savefig(os.path.join(save_path, 'test_predictions.png'))
    plt.close()

def plot_losses(train_losses, val_losses, save_path):
    plt.figure()
    epochs = range(1, len(train_losses)+1)
    plt.plot(epochs, train_losses, 'r', label='Training loss')
    plt.plot(epochs, val_losses, 'b', label='Validation loss')
    plt.title('Training and Validation losses')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.savefig(os.path.join(save_path, 'loss_plot.png'))
    plt.close()
python
Copy code
# main.py

from dataset import SegmentationDataset
from model import unet_model
from train import train_model, test_model, plot_losses
import os
import tensorflow as tf
import shutil

if __name__ == "__main__":
    # Parameters
    data_path = 'path_to_your_data'
    save_path = 'path_to_save_results'
    img_height = 256
    img_width = 256
    batch_size = 16
    epochs = 10

    # Load dataset
    dataset = SegmentationDataset(data_path, img_height=img_height, img_width=img_width)
    (img_train, mask_train), (img_val, mask_val), (img_test, mask_test) = dataset.split_dataset()
    print(f"Training set size: {len(img_train)}")
    print(f"Validation set size: {len(img_val)}")
    print(f"Test set size: {len(img_test)}")

    # Copy the splitted data
    train_dir = os.path.join(save_path, 'train')
    val_dir = os.path.join(save_path, 'val')
    test_dir = os.path.join(save_path, 'test')
    os.makedirs(os.path.join(train_dir, 'images'), exist_ok=True)
    os.makedirs(os.path.join(train_dir, 'masks'), exist_ok=True)
    os.makedirs(os.path.join(val_dir, 'images'), exist_ok=True)
    os.makedirs(os.path.join(val_dir, 'masks'), exist_ok=True)
    os.makedirs(os.path.join(test_dir, 'images'), exist_ok=True)
    os.makedirs(os.path.join(test_dir, 'masks'), exist_ok=True)

    def copy_files(image_paths, mask_paths, dest_dir):
        for img_path, mask_path in zip(image_paths, mask_paths):
            img_name = os.path.basename(img_path)
            mask_name = os.path.basename(mask_path)
            shutil.copy(img_path, os.path.join(dest_dir, 'images', img_name))
            shutil.copy(mask_path, os.path.join(dest_dir, 'masks', mask_name))

    copy_files(img_train, mask_train, train_dir)
    copy_files(img_val, mask_val, val_dir)
    copy_files(img_test, mask_test, test_dir)

    # DataLoader setup
    train_dataset = dataset.get_tf_data_generator(img_train, mask_train, batch_size=batch_size, shuffle=True)
    val_dataset = dataset.get_tf_data_generator(img_val, mask_val, batch_size=batch_size, shuffle=False)
    test_dataset = dataset.get_tf_data_generator(img_test, mask_test, batch_size=batch_size, shuffle=False)

    # Ensure correct data loading
    train_steps = len(img_train) // batch_size
    val_steps = len(img_val) // batch_size
    test_steps = len(img_test) // batch_size
    print(f"Train steps per epoch: {train_steps}")
    print(f"Validation steps: {val_steps}")
    print(f"Test steps: {test_steps}")

    # Build model
    model = unet_model(input_size=(img_height, img_width, 1))
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    model.summary()
    total_params = model.count_params()
    print(f"Total number of parameters: {total_params}")

    # Train model
    train_losses, val_losses = train_model(model, train_dataset, val_dataset, epochs, save_path)

    # Plot losses
    plot_losses(train_losses, val_losses, save_path)

    # Test model
    test_model(model, test_dataset, save_path, img_test)
This codebase is organized into four scripts as specified and includes all the functionalities you requested. Remember to replace 'path_to_your_data' and 'path_to_save_results' with your actual data and save paths. Ensure all necessary libraries (tensorflow, numpy, pandas, matplotlib, tqdm, etc.) are installed before running the code.